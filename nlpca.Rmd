---
output:
  word_document: default
  html_document: default
---
```{r}
setwd(dirname("G:/OneDrive/HCMUS_CaoHoc/Lu·∫≠n vƒÉn ƒë·ªÅ t√†i PCA/code"))
getwd()

```

## Section 1: Configuration v√† Setup

```{r}
# PH·∫¶N 2: TRI·ªÇN KHAI THU·∫¨T TO√ÅN GIFI::PRINCIPALS
# M·ª•c 1: Thi·∫øt l·∫≠p c·∫•u h√¨nh v√† m√¥-ƒëun h√≥a

# Thi·∫øt l·∫≠p ch√≠nh cho ph√¢n t√≠ch NLPCA
NLPCA_CONFIG <- list(
  # L·ª±a ch·ªçn ph∆∞∆°ng ph√°p - thi·∫øt k·∫ø d·∫°ng m√¥-ƒëun
  methods = list(
    gifi = TRUE,       # ƒêang tri·ªÉn khai ph∆∞∆°ng ph√°p n√†y
    homals = FALSE     # homal
  ),
  
  # Tham s·ªë ph√¢n t√≠ch
  parameters = list(
    ndim = 10,                    # S·ªë l∆∞·ª£ng th√†nh ph·∫ßn c·∫ßn tr√≠ch xu·∫•t
    max_iterations = 100,         # S·ªë v√≤ng l·∫∑p t·ªëi ƒëa cho thu·∫≠t to√°n h·ªôi t·ª•
    convergence_tolerance = 1e-6, # Ng∆∞·ª°ng h·ªôi t·ª• thu·∫≠t to√°n
    verbose = TRUE,               # Hi·ªÉn th·ªã chi ti·∫øt ti·∫øn tr√¨nh
    seed = 123                    # Gi√° tr·ªã kh·ªüi t·∫°o ng·∫´u nhi√™n (ƒë·ªÉ t√°i l·∫≠p k·∫øt qu·∫£)
  ),
  
  # Thi·∫øt l·∫≠p tr·ª±c quan h√≥a
  visualization = list(
    create_plots = TRUE,        # C√≥ th·ª±c hi·ªán v·∫Ω bi·ªÉu ƒë·ªì kh√¥ng
    save_plots = FALSE,         # C√≥ l∆∞u file bi·ªÉu ƒë·ªì kh√¥ng
    plot_width = 10,            # Chi·ªÅu r·ªông bi·ªÉu ƒë·ªì (inch)
    plot_height = 8             # Chi·ªÅu cao bi·ªÉu ƒë·ªì (inch)
  ),
  
  # Thi·∫øt l·∫≠p ƒë·∫ßu ra
  output = list(
    export_matrices = TRUE,         # Xu·∫•t c√°c ma tr·∫≠n k·∫øt qu·∫£
    detailed_analysis = TRUE,       # B√°o c√°o chi ti·∫øt ph√¢n t√≠ch
    prepare_for_variable_selection = TRUE  # Chu·∫©n b·ªã ƒë·∫ßu ra ph·ª•c v·ª• giai ƒëo·∫°n ch·ªçn bi·∫øn
  )
)


cat("Ho√†n t·∫•t c√°c thi·∫øt l·∫≠p ƒë·ªÉ tri·ªÉn khai thu·∫≠t to√°n NLPCA\n")

```

## Section 2: N·∫°p g√≥i th∆∞ vi·ªán v√† chu·∫©n b·ªã m√¥i tr∆∞·ªùng ph√¢n t√≠ch

```{r}
# M·ª•c 2: N·∫°p g√≥i th∆∞ vi·ªán v√† chu·∫©n b·ªã m√¥i tr∆∞·ªùng ph√¢n t√≠ch

cat("2.2 CHU·∫®N B·ªä M√îI TR∆Ø·ªúNG V√Ä D·ªÆ LI·ªÜU\n")
cat("\n\n")
cat("- Thi·∫øt l·∫≠p m√¥i tr∆∞·ªùng ph√¢n t√≠ch R ph√π h·ª£p ƒë·ªÉ ƒë·∫£m b·∫£o m·ªçi b∆∞·ªõc t√≠nh to√°n c√≥ th·ªÉ th·ª±c thi ·ªïn ƒë·ªãnh.\n")
cat("- Ki·ªÉm tra v√† c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt ph·ª•c v·ª• thu·∫≠t to√°n ph√¢n t√≠ch v√† tr·ª±c quan ho√° k·∫øt qu·∫£\n\n")

cat("2.2.1 C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt:\n")

# Nh√≥m g√≥i th∆∞ vi·ªán c·ªët l√µi cho tri·ªÉn khai gi·∫£i thu·∫≠t Gifi
gifi_packages <- c("Gifi", "MASS", "psych")
# C√°c th∆∞ vi·ªán ƒë·ªÉ tr·ª±c quan ho√° d·ªØ li·ªáu
viz_packages <- c("ggplot2", "corrplot", "RColorBrewer", "gridExtra", "knitr")

# C√°c g√≥i ƒë·ªÉ tr·ª±c quan ho√° d·ªØ li·ªáu
required_packages <- gifi_packages
if(NLPCA_CONFIG$visualization$create_plots) {
  required_packages <- c(required_packages, viz_packages)
}

# Ki·ªÉm tra c√†i ƒë·∫∑t c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt
for(pkg in required_packages) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    install.packages(pkg, quiet = TRUE)
  }
  library(pkg, character.only = TRUE, quietly = TRUE)
}

cat("‚úì ƒê√£ c√†i ƒë·∫∑t", length(required_packages), "th∆∞ vi·ªán cho tri·ªÉn khai gi·∫£i thu·∫≠t Gifi\n\n")
```

## Section 3: Load d·ªØ li·ªáu

```{r}
# Section 3: ƒê·ªçc d·ªØ li·ªáu marketing_data.csv
cat("2.2.2 ƒê·ªçc d·ªØ li·ªáu t·ª´ file csv:\n")
df_raw <- read.csv("marketing_data.csv", stringsAsFactors = FALSE)

cat("ƒê√£ ƒë·ªçc file d·ªØ li·ªáu marketing_data th√†nh c√¥ng\n")
cat("K√≠ch th∆∞·ªõc b·ªô d·ªØ li·ªáu:", dim(df_raw), "\n")
cat("M·ªôt s·ªë t√™n bi·∫øn m·∫´u:", paste(names(df_raw)[1:5], collapse = ", "), "...\n\n")

# Hi·ªÉn th·ªã c·∫•u tr√∫c t·ªïng qu√°t c·ªßa b·ªô d·ªØ li·ªáu ƒë·ªÉ ki·ªÉm tra nhanh lo·∫°i bi·∫øn v√† format
str(df_raw)
# L∆∞u l·∫°i th√†nh file df_raw ƒë·ªÉ t√°i s·ª≠ d·ª•ng
write.csv(df_raw, "df_raw.csv", row.names = FALSE)
cat("L∆∞u file df_raw th√†nh c√¥ng\n")
```

## Section 4: Kh√°m ph√° c·∫•u tr√∫c d·ªØ li·ªáu

```{r}
# Section 4: Kh√°m ph√° c·∫•u tr√∫c d·ªØ li·ªáu

cat("Kh√°m ph√° c·∫•u tr√∫c d·ªØ li·ªáu:\n")

# Hi·ªÉn th·ªã c·∫•u tr√∫c d·ªØ li·ªáu
cat("- S·ªë d√≤ng (observations):", nrow(df_raw), "\n")
cat("- S·ªë c·ªôt (variables):", ncol(df_raw), "\n")

# Hi·ªÉn th·ªã t√™n t·∫•t c·∫£ c√°c c·ªôt
cat("\nHi·ªÉn th·ªã t√™n t·∫•t c·∫£ c√°c c·ªôt:\n")
for(i in 1:ncol(df_raw)) {
  cat(sprintf("%2d. %-20s", i, names(df_raw)[i]))
  if(i %% 3 == 0) cat("\n") else cat("  ")
}
if(ncol(df_raw) %% 3 != 0) cat("\n")

# Hi·ªÉn th·ªã 5 d√≤ng ƒë·∫ßu ƒë·ªÉ ki·ªÉm tra format d·ªØ li·ªáu
cat("\nFIRST 5 ROWS:\n")
print(head(df_raw, 5))
```

## Section 5: Th·ªëng k√™ m√¥ t·∫£

```{r}
# M·ª•c 5: Th·ªëng k√™ m√¥ t·∫£ c∆° b·∫£n

cat("\n TH·ªêNG K√ä M√î T·∫¢ C∆† B·∫¢N\n")
cat("==============================\n")

cat("\nA. Th·ªëng k√™ c∆° b·∫£n cho bi·∫øn s·ªë (numeric):\n")
numeric_cols <- names(df_raw)[sapply(df_raw, is.numeric)]
sample_numeric <- numeric_cols[1:min(6, length(numeric_cols))]

for(col in sample_numeric) {
  if(col != "ID") {  # B·ªè qua bi·∫øn ƒë·ªãnh danh ID
    values <- df_raw[[col]][!is.na(df_raw[[col]])]
    if(length(values) > 0) {
      cat(sprintf("%-20s: Min = %8.0f, Max = %8.0f, Mean = %8.2f, Median = %8.0f\n", 
                  col, min(values), max(values), mean(values), median(values)))
    }
  }
}

cat("\nB. Th·ªëng k√™ cho bi·∫øn ph√¢n lo·∫°i (categorical):\n")
categorical_cols <- names(df_raw)[sapply(df_raw, function(x) is.character(x) | is.factor(x))]

for(col in categorical_cols[1:min(3, length(categorical_cols))]) {
  unique_vals <- unique(df_raw[[col]])
  unique_vals <- unique_vals[!is.na(unique_vals) & unique_vals != ""]
  cat(sprintf("%-20s: %2d gi√° tr·ªã duy nh·∫•t", col, length(unique_vals)))
  
  if(length(unique_vals) <= 8) {
    cat(" [", paste(unique_vals[1:min(5, length(unique_vals))], collapse=", "), "]")
    if(length(unique_vals) > 5) cat("...")
  }
  cat("\n")
}

# Ph√°t hi·ªán gi√° tr·ªã ngo·∫°i lai cho thu nh·∫≠p (Income)
if(" Income " %in% names(df_raw) || "Income" %in% names(df_raw)) {
  income_col <- ifelse(" Income " %in% names(df_raw), " Income ", "Income")
  cat("\nPH√ÇN T√çCH GI√Å TR·ªä NGO·∫†I LAI (Income):\n")
  
  income_clean <- gsub("[$,\\s]", "", df_raw[[income_col]])
  income_numeric <- as.numeric(income_clean)
  income_numeric <- income_numeric[!is.na(income_numeric)]
  
  if(length(income_numeric) > 0) {
    Q1 <- quantile(income_numeric, 0.25)
    Q3 <- quantile(income_numeric, 0.75)
    IQR <- Q3 - Q1
    outliers <- income_numeric[income_numeric < (Q1 - 1.5 * IQR) | income_numeric > (Q3 + 1.5 * IQR)]
    
    cat("- Q1 (T·ª© ph√¢n v·ªã th·ª© nh·∫•t): $", round(Q1, 0), 
        ", Q3 (T·ª© ph√¢n v·ªã th·ª© ba): $", round(Q3, 0), "\n", sep="")
    cat("- S·ªë l∆∞·ª£ng gi√° tr·ªã ngo·∫°i lai ti·ªÅm nƒÉng:", length(outliers), "quan s√°t (", 
        round(length(outliers)/length(income_numeric)*100, 2), "%)\n", sep="")
    
    
  }
}

cat("\n ƒê√£ ho√†n th√†nh b∆∞·ªõc th·ªëng k√™ m√¥ t·∫£ d·ªØ li·ªáu\n")


```
## Section 6: Ph√¢n t√≠ch ki·ªÉu d·ªØ li·ªáu v√† missing values

```{r}
# M·ª•c 6: Ki·ªÉm tra ki·ªÉu d·ªØ li·ªáu v√† d·ªØ li·ªáu thi·∫øu (missing values)

cat("\n2.2.3 PH√ÇN T√çCH KI·ªÇU D·ªÆ LI·ªÜU V√Ä D·ªÆ LI·ªÜU THI·∫æU\n")
cat("\n\n")

# Ph√¢n t√≠ch ki·ªÉu d·ªØ li·ªáu c·ªßa t·ª´ng bi·∫øn trong b·ªô d·ªØ li·ªáu g·ªëc
cat("Ki·ªÉu d·ªØ li·ªáu c·ªßa c√°c bi·∫øn:\n")
data_types <- sapply(df_raw, class)
type_summary <- table(data_types)
for(type in names(type_summary)) {
  cat(sprintf("- %s bi·∫øn l√† %-12s\n", type, type_summary[type]))
}

# Ki·ªÉm tra s·ª± xu·∫•t hi·ªán c·ªßa gi√° tr·ªã thi·∫øu (missing values)
cat("\nKi·ªÉm tra d·ªØ li·ªáu thi·∫øu (missing values):\n")
missing_counts <- sapply(df_raw, function(x) sum(is.na(x) | x == "" | x == " "))
total_missing <- sum(missing_counts)

if(total_missing > 0) {
  cat("C√°c bi·∫øn c√≥ d·ªØ li·ªáu thi·∫øu:\n")
  missing_vars <- missing_counts[missing_counts > 0]
  for(var in names(missing_vars)) {
    pct <- round(missing_vars[var] / nrow(df_raw) * 100, 2)
    cat(sprintf("- %-18s: %4d missing (%.2f%%)\n", var, missing_vars[var], pct))
  }
} else {
  cat("‚úì Kh√¥ng ph√°t hi·ªán d·ªØ li·ªáu thi·∫øu trong b·ªô d·ªØ li·ªáu.\n")
}

# T·∫°o b·∫£ng t√≥m t·∫Øt ki·ªÉu d·ªØ li·ªáu v√† s·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu
summary_types <- data.frame(
  Bi·∫øn = names(df_raw),
  `Ki·ªÉu d·ªØ li·ªáu` = sapply(df_raw, class),
  `S·ªë l∆∞·ª£ng missing` = sapply(df_raw, function(x) sum(is.na(x) | x == "" | x == " "))
)
cat("\nB·∫£ng t√≥m t·∫Øt ki·ªÉu d·ªØ li·ªáu v√† s·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu c·ªßa t·ª´ng bi·∫øn:\n")
kable(summary_types, caption = "B·∫£ng t√≥m t·∫Øt ki·ªÉu d·ªØ li·ªáu v√† s·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu")


```



## Section 7: Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu

```{r}

cat("2.2.5 TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU:\n")
cat("============================\n")

# T·∫°o b·∫£n sao ƒë·ªÉ x·ª≠ l√Ω, ƒë·∫£m b·∫£o d·ªØ li·ªáu g·ªëc kh√¥ng b·ªã ·∫£nh h∆∞·ªüng
df_clean <- df_raw

# X·ª≠ l√Ω c·ªôt Income: chuy·ªÉn t·ª´ ƒë·ªãnh d·∫°ng text sang numeric ƒë·ªÉ thu·∫≠n ti·ªán cho ph√¢n t√≠ch th·ªëng k√™
income_col <- names(df_clean)[grepl("Income", names(df_clean), ignore.case = TRUE)]
if(length(income_col) > 0) {
  cat("ƒê√£ ph√°t hi·ªán bi·∫øn thu nh·∫≠p:", income_col[1], "\n")
  df_clean$Income_Clean <- as.numeric(gsub("[$,\\s]", "", df_clean[[income_col[1]]]))
  cat("- ƒê√£ chuy·ªÉn ƒë·ªïi bi·∫øn thu nh·∫≠p sang ki·ªÉu s·ªë (numeric)\n")
} else {
  stop("Kh√¥ng t√¨m th·∫•y bi·∫øn Income trong d·ªØ li·ªáu ‚Äì vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c d·ªØ li·ªáu")
}

# T√≠nh bi·∫øn tu·ªïi (Age) t·ª´ bi·∫øn nƒÉm sinh (Year_Birth)
if("Year_Birth" %in% names(df_clean)) {
  df_clean$Age <- 2024 - df_clean$Year_Birth
  cat("- ƒê√£ t·∫°o bi·∫øn Age t·ª´ Year_Birth\n")
} else {
  stop("Kh√¥ng c√≥ bi·∫øn Year_Birth ‚Äì kh√¥ng th·ªÉ t√≠nh tu·ªïi")
}

# Lo·∫°i b·ªè c√°c bi·∫øn kh√¥ng ph·ª•c v·ª• tr·ª±c ti·∫øp cho ph√¢n t√≠ch NLPCA
variables_to_remove <- c("ID", "Year_Birth", "Income", "Dt_Customer")
available_to_remove <- variables_to_remove[variables_to_remove %in% names(df_clean)]

if(length(available_to_remove) > 0) {
  cat("\nLo·∫°i b·ªè c√°c bi·∫øn kh√¥ng c·∫ßn thi·∫øt:\n")
  for(var in available_to_remove) {
    cat(sprintf("- Lo·∫°i b·ªè %s: ", var))
    if(var == "ID") {
      cat("Bi·∫øn ƒë·ªãnh danh (kh√¥ng ph·ª•c v·ª• ph√¢n t√≠ch)\n")
    } else if(var == "Year_Birth") {
      cat("ƒê√£ chuy·ªÉn ƒë·ªïi sang bi·∫øn Age\n")
    } else if(var == "Income") {
      cat("ƒê√£ ƒë∆∞·ª£c thay th·∫ø b·ªüi Income_Clean\n")
    } else if(var == "Dt_Customer") {
      cat("Bi·∫øn ng√†y th√°ng (kh√¥ng ph√π h·ª£p v·ªõi NLPCA)\n")
    }
  }
  # Lo·∫°i b·ªè c√°c bi·∫øn
  df_clean <- df_clean[, !names(df_clean) %in% available_to_remove, drop = FALSE]
  cat(sprintf("‚úì ƒê√£ lo·∫°i b·ªè %d bi·∫øn\n", length(available_to_remove)))
} else {
  cat("- Kh√¥ng ph√°t hi·ªán bi·∫øn n√†o c·∫ßn lo·∫°i b·ªè\n")
}

# Lo·∫°i b·ªè c√°c d√≤ng thi·∫øu d·ªØ li·ªáu ·ªü Income_Clean ƒë·ªÉ ƒë·∫£m b·∫£o ph√¢n t√≠ch complete case
initial_rows <- nrow(df_clean)
df_clean <- df_clean[!is.na(df_clean$Income_Clean), ]
final_rows <- nrow(df_clean)

if(initial_rows != final_rows) {
  cat(sprintf("- ƒê√£ lo·∫°i b·ªè %d d√≤ng thi·∫øu d·ªØ li·ªáu Income_Clean\n", initial_rows - final_rows))
}

cat(sprintf("‚úì K√≠ch th∆∞·ªõc d·ªØ li·ªáu s·∫°ch: %d √ó %d\n", nrow(df_clean), ncol(df_clean)))
cat(sprintf("- S·ªë l∆∞·ª£ng bi·∫øn ƒë√£ gi·∫£m t·ª´ %d c√≤n %d\n", ncol(df_raw), ncol(df_clean)))
cat("‚úì ƒê√£ ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu!\n\n")

# Hi·ªÉn th·ªã c·∫•u tr√∫c b·ªô d·ªØ li·ªáu sau ti·ªÅn x·ª≠ l√Ω
cat("C·∫•u tr√∫c d·ªØ li·ªáu cu·ªëi c√πng sau ti·ªÅn x·ª≠ l√Ω:\n")
cat(sprintf("- S·ªë quan s√°t (observations): %d\n", nrow(df_clean)))
cat(sprintf("- S·ªë bi·∫øn (variables): %d\n", ncol(df_clean)))
cat(sprintf("- C√°c bi·∫øn ƒë√£ lo·∫°i b·ªè: %s\n", paste(available_to_remove, collapse = ", ")))
cat("- C√°c bi·∫øn d·∫´n xu·∫•t quan tr·ªçng: Age (t·ª´ Year_Birth), Income_Clean (t·ª´ Income)\n")


write.csv(df_clean, "df_clean.csv", row.names = FALSE)
cat("L∆∞u file df_clean th√†nh c√¥ng")

```
## Section 8: X√°c ƒë·ªãnh thang ƒëo ph√π h·ª£p cho c√°c bi·∫øn

```{r}
# Ph·∫ßn 8: X√°c ƒë·ªãnh thang ƒëo ph√π h·ª£p cho c√°c bi·∫øn
cat("2.2.5 X√°c ƒë·ªãnh thang ƒëo ph√π h·ª£p cho c√°c bi·∫øn:\n")

# Hi·ªÉn th·ªã danh s√°ch t·∫•t c·∫£ c√°c bi·∫øn trong b·ªô d·ªØ li·ªáu
cat("Danh s√°ch t·∫•t c·∫£ c√°c bi·∫øn trong b·ªô d·ªØ li·ªáu:\n")
all_cols <- names(df_clean)
for(i in 1:length(all_cols)) {
  cat(sprintf("%2d. %-20s (%s)\n", i, all_cols[i], class(df_clean[[all_cols[i]]])))
}

# X√°c ƒë·ªãnh c√°c bi·∫øn ƒë·ªãnh l∆∞·ª£ng (numeric)
numerical_vars <- names(df_clean)[sapply(df_clean, is.numeric)]
# Lo·∫°i tr·ª´ c√°c bi·∫øn kh√¥ng ph·ª•c v·ª• ph√¢n t√≠ch ƒë·ªãnh l∆∞·ª£ng
exclude_numeric <- c("ID", "Year_Birth")  # Year_Birth ƒë√£ ƒë∆∞·ª£c chuy·ªÉn th√†nh Age
numerical_vars <- numerical_vars[!numerical_vars %in% exclude_numeric]

cat("\nC√°c bi·∫øn ƒë·ªãnh l∆∞·ª£ng:\n")
for(i in 1:length(numerical_vars)) {
  cat(sprintf("%2d. %s\n", i, numerical_vars[i]))
}

# X√°c ƒë·ªãnh c√°c bi·∫øn ƒë·ªãnh t√≠nh (categorical)
categorical_vars <- names(df_clean)[sapply(df_clean, function(x) is.character(x) | is.factor(x))]
# Lo·∫°i tr·ª´ c√°c bi·∫øn ƒë·ªãnh t√≠nh kh√¥ng c·∫ßn thi·∫øt n·∫øu c√≥
exclude_categorical <- c()
categorical_vars <- categorical_vars[!categorical_vars %in% exclude_categorical]

cat("\nC√°c bi·∫øn ƒë·ªãnh t√≠nh:\n")
for(i in 1:length(categorical_vars)) {
  unique_count <- length(unique(df_clean[[categorical_vars[i]]]))
  cat(sprintf("%2d. %-20s (%d gi√° tr·ªã duy nh·∫•t)\n", i, categorical_vars[i], unique_count))
}

# T·∫°o danh s√°ch bi·∫øn cu·ªëi c√πng
available_num_vars <- numerical_vars[numerical_vars %in% names(df_clean)]
available_cat_vars <- categorical_vars[categorical_vars %in% names(df_clean)]

cat("\nT·ªïng k·∫øt s·ªë l∆∞·ª£ng bi·∫øn:\n")
cat("Bi·∫øn ƒë·ªãnh l∆∞·ª£ng (metric):", length(available_num_vars), "\n")
cat("Bi·∫øn ƒë·ªãnh t√≠nh:", length(available_cat_vars), "\n")
cat("T·ªîNG s·ªë bi·∫øn s·ª≠ d·ª•ng cho NLPCA:", length(available_num_vars) + length(available_cat_vars), "\n")

# T·∫°o t·∫≠p d·ªØ li·ªáu NLPCA v·ªõi to√†n b·ªô bi·∫øn ƒë√£ ch·ªçn
mixed_vars <- c(available_num_vars, available_cat_vars)
nlpca_data <- df_clean[, mixed_vars, drop = FALSE]
nlpca_data <- nlpca_data[complete.cases(nlpca_data), ]

# L∆∞u d·ªØ li·ªáu ra file CSV
write.csv(nlpca_data, "nlpca_data.csv", row.names = FALSE)


# X√°c ƒë·ªãnh thang ƒëo ph√π h·ª£p cho t·ª´ng bi·∫øn
measurement_levels <- character(length(mixed_vars))
names(measurement_levels) <- mixed_vars

# G√°n thang ƒëo "metric" cho bi·∫øn ƒë·ªãnh l∆∞·ª£ng
measurement_levels[available_num_vars] <- "metric"

# G√°n thang ƒëo cho bi·∫øn ƒë·ªãnh t√≠nh: x√°c ƒë·ªãnh "ordinal" hay "nominal"
for(var in available_cat_vars) {
  unique_vals <- unique(df_clean[[var]])
  unique_vals <- unique_vals[!is.na(unique_vals) & unique_vals != ""]
  
  # Quy t·∫Øc x√°c ƒë·ªãnh thang ƒëo
  if(var == "Education" || grepl("education|degree|level", var, ignore.case = TRUE)) {
    measurement_levels[var] <- "ordinal"
    cat("ƒê·∫∑t", var, "l√† BI·∫æN TH·ª® B·∫¨C (ph√°t hi·ªán c·∫•u tr√∫c ph√¢n c·∫•p h·ªçc v·∫•n)\n")
  } else if(length(unique_vals) > 10) {
    measurement_levels[var] <- "nominal"
    cat("ƒê·∫∑t", var, "l√† BI·∫æN ƒê·ªäNH DANH (s·ªë l∆∞·ª£ng m·ª©c l·ªõn:", length(unique_vals), "gi√° tr·ªã)\n")
  } else {
    measurement_levels[var] <- "nominal"
    cat("ƒê·∫∑t", var, "l√† BI·∫æN ƒê·ªäNH DANH (", length(unique_vals), "gi√° tr·ªã)\n")
  }
}

cat("\nK√≠ch th∆∞·ªõc b·ªô d·ªØ li·ªáu NLPCA cu·ªëi c√πng:", nrow(nlpca_data), "quan s√°t √ó", ncol(nlpca_data), "bi·∫øn\n")

# Hi·ªÉn th·ªã t√≥m t·∫Øt thang ƒëo c·ªßa c√°c bi·∫øn
cat("\nB·∫£ng t·ªïng h·ª£p thang ƒëo c·ªßa c√°c bi·∫øn:\n")
for(var in names(measurement_levels)) {
  if(var %in% available_cat_vars) {
    cat(sprintf("‚Ä¢ %-20s: %s\n", var, toupper(measurement_levels[var])))
  }
}
cat(sprintf("‚Ä¢ %-20s: %s (%d bi·∫øn)\n", "Bi·∫øn ƒë·ªãnh l∆∞·ª£ng", "METRIC", length(available_num_vars)))

# Th·ªëng k√™ s·ªë l∆∞·ª£ng t·ª´ng lo·∫°i thang ƒëo
cat("\nT√≥m t·∫Øt ph√¢n b·ªë thang ƒëo:\n")
ordinal_vars <- sum(measurement_levels == "ordinal", na.rm = TRUE)
nominal_vars <- sum(measurement_levels == "nominal", na.rm = TRUE)
metric_vars <- sum(measurement_levels == "metric", na.rm = TRUE)

cat(sprintf("‚Ä¢ TH·ª® B·∫¨C: %d bi·∫øn\n", ordinal_vars))
cat(sprintf("‚Ä¢ ƒê·ªäNH DANH: %d bi·∫øn\n", nominal_vars))
cat(sprintf("‚Ä¢ ƒê·ªäNH L∆Ø·ª¢NG: %d bi·∫øn\n", metric_vars))
cat(sprintf("‚Ä¢ T·ªîNG: %d bi·∫øn (d·ª± ki·∫øn kho·∫£ng 28)\n", length(measurement_levels)))

# Ki·ªÉm tra t√≠nh nh·∫•t qu√°n gi·ªØa s·ªë bi·∫øn v√† s·ªë thang ƒëo ƒë√£ x√°c ƒë·ªãnh
if(length(measurement_levels) != length(mixed_vars)) {
  cat(" C·∫¢NH B√ÅO: S·ªë l∆∞·ª£ng thang ƒëo kh√¥ng kh·ªõp v·ªõi s·ªë bi·∫øn!\n")
} else {
  cat("‚úì ƒê√£ x√°c ƒë·ªãnh thang ƒëo ph√π h·ª£p cho to√†n b·ªô bi·∫øn\n")
}
```


## Section 9: Chu·∫©n h√≥a d·ªØ li·ªáu
```{r}
# Section 9: CHU·∫®N H√ìA D·ªÆ LI·ªÜU (Z-SCORE STANDARDIZATION)
cat("2.2.6 CHU·∫®N H√ìA D·ªÆ LI·ªÜU (Z-SCORE STANDARDIZATION):\n")
cat("================================================\n")

# H√†m chu·∫©n h√≥a cho d·ªØ li·ªáu h·ªón h·ª£p
standardize_mixed_data <- function(data, measurement_levels, verbose = TRUE) {
  
  if(verbose) cat("B·∫Øt ƒë·∫ßu chu·∫©n h√≥a d·ªØ li·ªáu h·ªón h·ª£p:\n")
  
  standardized_data <- data
  standardization_info <- list()
  
  # Chu·∫©n h√≥a bi·∫øn ƒë·ªãnh l∆∞·ª£ng (numeric variables)
  numeric_vars <- names(measurement_levels)[measurement_levels == "metric"]
  numeric_vars <- intersect(numeric_vars, names(data))
  
  if(length(numeric_vars) > 0) {
    if(verbose) cat(sprintf("Chu·∫©n h√≥a %d bi·∫øn ƒë·ªãnh l∆∞·ª£ng:\n", length(numeric_vars)))
    
    for(var in numeric_vars) {
      if(is.numeric(data[[var]])) {
        # T√≠nh mean v√† sd
        var_mean <- mean(data[[var]], na.rm = TRUE)
        var_sd <- sd(data[[var]], na.rm = TRUE)
        
        # Z-score standardization: (x - Œº) / œÉ
        standardized_data[[var]] <- scale(data[[var]], center = TRUE, scale = TRUE)[, 1]
        
        # L∆∞u th√¥ng tin chu·∫©n h√≥a
        standardization_info[[var]] <- list(
          type = "z_score",
          mean = var_mean,
          sd = var_sd,
          min_original = min(data[[var]], na.rm = TRUE),
          max_original = max(data[[var]], na.rm = TRUE),
          min_standardized = min(standardized_data[[var]], na.rm = TRUE),
          max_standardized = max(standardized_data[[var]], na.rm = TRUE)
        )
        
        if(verbose) {
          cat(sprintf("  ‚Ä¢ %s: Œº=%.2f, œÉ=%.2f ‚Üí Z-score range [%.2f, %.2f]\n", 
                      var, var_mean, var_sd, 
                      standardization_info[[var]]$min_standardized,
                      standardization_info[[var]]$max_standardized))
        }
      }
    }
  }
  
  # Bi·∫øn ƒë·ªãnh t√≠nh kh√¥ng c·∫ßn chu·∫©n h√≥a (ch·ªâ ghi nh·∫≠n)
  categorical_vars <- names(measurement_levels)[measurement_levels %in% c("nominal", "ordinal")]
  categorical_vars <- intersect(categorical_vars, names(data))
  
  if(length(categorical_vars) > 0 && verbose) {
    cat(sprintf("Gi·ªØ nguy√™n %d bi·∫øn ƒë·ªãnh t√≠nh (kh√¥ng chu·∫©n h√≥a):\n", length(categorical_vars)))
    for(var in categorical_vars) {
      n_levels <- length(unique(data[[var]]))
      standardization_info[[var]] <- list(
        type = "categorical",
        levels = n_levels
      )
      cat(sprintf("  ‚Ä¢ %s: %d levels\n", var, n_levels))
    }
  }
  
  return(list(
    data = standardized_data,
    standardization_info = standardization_info,
    numeric_vars_standardized = numeric_vars,
    categorical_vars_unchanged = categorical_vars
  ))
}

# √Åp d·ª•ng chu·∫©n h√≥a cho d·ªØ li·ªáu s·∫°ch
cat("Chu·∫©n h√≥a d·ªØ li·ªáu cho ph√¢n t√≠ch NLPCA:\n")

standardization_result <- standardize_mixed_data(
  nlpca_data, 
  measurement_levels, 
  verbose = TRUE
)

# C·∫≠p nh·∫≠t d·ªØ li·ªáu NLPCA v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
nlpca_data_standardized <- standardization_result$data

cat("\n‚úì ƒê√£ ho√†n th√†nh chu·∫©n h√≥a d·ªØ li·ªáu\n")
cat(sprintf("‚Ä¢ %d bi·∫øn ƒë·ªãnh l∆∞·ª£ng ƒë∆∞·ª£c chu·∫©n h√≥a Z-score\n", 
            length(standardization_result$numeric_vars_standardized)))
cat(sprintf("‚Ä¢ %d bi·∫øn ƒë·ªãnh t√≠nh gi·ªØ nguy√™n\n", 
            length(standardization_result$categorical_vars_unchanged)))

# Ki·ªÉm tra k·∫øt qu·∫£ chu·∫©n h√≥a
cat("\nKi·ªÉm tra ch·∫•t l∆∞·ª£ng chu·∫©n h√≥a:\n")
for(var in standardization_result$numeric_vars_standardized) {
  if(var %in% names(nlpca_data_standardized)) {
    actual_mean <- mean(nlpca_data_standardized[[var]], na.rm = TRUE)
    actual_sd <- sd(nlpca_data_standardized[[var]], na.rm = TRUE)
    cat(sprintf("‚Ä¢ %s: mean ‚âà %.3f, sd ‚âà %.3f %s\n", 
                var, actual_mean, actual_sd,
                ifelse(abs(actual_mean) < 0.001 && abs(actual_sd - 1) < 0.001, "‚úì", "‚ö†")))
  }
}

# C·∫≠p nh·∫≠t d·ªØ li·ªáu cho NLPCA
cat("\n‚Üí S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a cho c√°c b∆∞·ªõc ti·∫øp theo\n")
nlpca_data <- nlpca_data_standardized

write.csv(nlpca_data_standardized, "nlpca_data_standardized.csv", row.names = FALSE)
cat("\n L∆∞u file nlpca_data_standardize th√†nh c√¥ng. \n")

```


## Section 10: Tri·ªÉn khai Gifi analysis function

```{r}
cat("\n2.3 TRI·ªÇN KHAI GIFI::PRINCIPALS\n")
cat("===============================\n")

# H√†m tri·ªÉn khai ph√¢n t√≠ch Gifi v·ªõi thi·∫øt k·∫ø m√¥-ƒëun
run_gifi_analysis <- function(data, measurement_levels, config) {
  cat("2.3.1 Chu·∫©n b·ªã d·ªØ li·ªáu cho thu·∫≠t to√°n Gifi:\n")
  
  # Chu·∫©n b·ªã d·ªØ li·ªáu ƒë·∫ßu v√†o cho Gifi
  gifi_data <- data
  
  # Chuy·ªÉn c√°c bi·∫øn ƒë·ªãnh t√≠nh v·ªÅ ki·ªÉu factor ƒë√∫ng v·ªõi thang ƒëo
  categorical_vars <- names(measurement_levels)[measurement_levels %in% c("ordinal", "nominal")]
  
  cat(sprintf("Ti·ªÅn x·ª≠ l√Ω %d bi·∫øn ƒë·ªãnh t√≠nh (categorical):\n", length(categorical_vars)))
  
  for(col in categorical_vars) {
    if(measurement_levels[col] == "ordinal") {
      # X·ª≠ l√Ω bi·∫øn th·ª© b·∫≠c
      if(col == "Education") {
        # X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho Education v·ªõi th·ª© b·∫≠c h·ªçc v·∫•n ƒë√£ bi·∫øt
        education_order <- c("Basic", "2n Cycle", "Graduation", "Master", "PhD")
        available_levels <- intersect(education_order, unique(gifi_data[[col]]))
        gifi_data[[col]] <- factor(gifi_data[[col]], levels = available_levels, ordered = TRUE)
        cat(sprintf("  %s: ordered factor (%d m·ª©c) - Th·ª© b·∫≠c gi√°o d·ª•c\n", col, length(available_levels)))
      } else {
        # X·ª≠ l√Ω chung cho c√°c bi·∫øn th·ª© b·∫≠c kh√°c
        unique_vals <- sort(unique(gifi_data[[col]]))
        gifi_data[[col]] <- factor(gifi_data[[col]], levels = unique_vals, ordered = TRUE)
        cat(sprintf("  %s: ordered factor (%d m·ª©c) - Th·ª© b·∫≠c t·ª± nhi√™n\n", col, length(unique_vals)))
      }
    } else {
      # X·ª≠ l√Ω bi·∫øn ƒë·ªãnh danh
      gifi_data[[col]] <- factor(gifi_data[[col]])
      cat(sprintf("  %s: nominal factor (%d m·ª©c)\n", col, nlevels(gifi_data[[col]])))
    }
  }
  
  cat("\n2.3.2 Th·ª±c thi h√†m Gifi::princals():\n")
  cat("Tham s·ªë th·ª±c thi:\n")
  cat(sprintf("  ‚Ä¢ ndim = %d\n", config$parameters$ndim))
  cat(sprintf("  ‚Ä¢ itmax = %d\n", config$parameters$max_iterations))
  cat(sprintf("  ‚Ä¢ eps = %.0e\n", config$parameters$convergence_tolerance))
  cat(sprintf("  ‚Ä¢ verbose = %s\n", config$parameters$verbose))
  cat(sprintf("  ‚Ä¢ T·ªïng s·ªë bi·∫øn: %d (%d ƒë·ªãnh l∆∞·ª£ng + %d ƒë·ªãnh t√≠nh)\n", 
              length(measurement_levels), 
              sum(measurement_levels == "metric"),
              length(categorical_vars)))
  
  # ƒê·∫∑t seed ƒë·ªÉ k·∫øt qu·∫£ c√≥ th·ªÉ t√°i l·∫∑p
  set.seed(config$parameters$seed)
  
  # Th·ª±c thi thu·∫≠t to√°n Gifi PRINCIPALS
  tryCatch({
    cat("\nƒêang ch·∫°y Gifi::princals()...\n")
    cat(paste(rep("=", 50), collapse = ""), "\n")
    
    gifi_result <- Gifi::princals(
      data = gifi_data,
      ndim = config$parameters$ndim,
      levels = measurement_levels,
      verbose = config$parameters$verbose,
      itmax = config$parameters$max_iterations,
      eps = config$parameters$convergence_tolerance
    )
    
    cat("\n‚úì ƒê√£ th·ª±c thi th√†nh c√¥ng Gifi PRINCIPALS!\n")
    
    # Tr√≠ch xu·∫•t k·∫øt qu·∫£
    results <- list(
      method = "gifi",
      success = TRUE,
      object_scores = gifi_result$objectscores,
      loadings = gifi_result$loadings,
      eigenvalues = gifi_result$evals,
      quantifications = gifi_result$quantifications,
      loss_function = gifi_result$f,
      iterations = gifi_result$ntel,
      data_used = gifi_data
    )
    
    cat("\n2.3.3 Tr√≠ch xu·∫•t k·∫øt qu·∫£:\n")
    cat(sprintf("  ‚Ä¢ S·ªë v√≤ng l·∫∑p ALS: %d\n", results$iterations))
    cat(sprintf("  ‚Ä¢ Gi√° tr·ªã loss cu·ªëi c√πng: %.6f\n", results$loss_function))
    cat(sprintf("  ‚Ä¢ Ma tr·∫≠n ƒëi·ªÉm th√†nh ph·∫ßn: %d √ó %d\n", nrow(results$object_scores), ncol(results$object_scores)))
    cat(sprintf("  ‚Ä¢ Ma tr·∫≠n t·∫£i bi·∫øn: %d √ó %d\n", nrow(results$loadings), ncol(results$loadings)))
    cat(sprintf("  ‚Ä¢ Eigenvalues: %s\n", paste(round(results$eigenvalues, 4), collapse = ", ")))
    
    # T·ªïng h·ª£p c√°c bi·∫øn ƒë·ªãnh t√≠nh ƒë√£ x·ª≠ l√Ω
    cat(sprintf("  ‚Ä¢ S·ªë bi·∫øn ƒë·ªãnh t√≠nh ƒë√£ x·ª≠ l√Ω: %d\n", length(categorical_vars)))
    cat(sprintf("    - Ordinal (th·ª© b·∫≠c): %d\n", sum(measurement_levels == "ordinal")))
    cat(sprintf("    - Nominal (ƒë·ªãnh danh): %d\n", sum(measurement_levels == "nominal")))
    
    return(results)
    
  }, error = function(e) {
    cat("‚úó Gifi::princals() th·∫•t b·∫°i:", e$message, "\n")
    cat("Nguy√™n nh√¢n c√≥ th·ªÉ:\n")
    cat("  ‚Ä¢ S·ªë m·ª©c c·ªßa bi·∫øn ƒë·ªãnh t√≠nh qu√° l·ªõn g√¢y l·ªói b·ªô nh·ªõ\n")
    cat("  ‚Ä¢ T·∫≠p bi·∫øn c√≥ hi·ªán t∆∞·ª£ng ƒëa c·ªông tuy·∫øn (collinear)\n")
    cat("  ‚Ä¢ Thang ƒëo c·ªßa bi·∫øn ch∆∞a h·ª£p l·ªá ho·∫∑c thi·∫øu\n")
    return(list(method = "gifi", success = FALSE, error = e$message))
  })
}
```

## Section 11: Th·ª±c thi thu·∫≠t to√°n Gifi Analysis

```{r}
# Th·ª±c thi ph√¢n t√≠ch Gifi
results_list <- list()

if(NLPCA_CONFIG$methods$gifi) {
  cat("Th·ª±c thi ph√¢n t√≠ch Gifi...\n")
  gifi_results <- run_gifi_analysis(nlpca_data_standardized, measurement_levels, NLPCA_CONFIG)
  results_list$gifi <- gifi_results
}

# L·ª±a ch·ªçn k·∫øt qu·∫£ ch√≠nh
if(results_list$gifi$success) {
  primary_results <- results_list$gifi
  cat("\nPh∆∞∆°ng ph√°p s·ª≠ d·ª•ng ch√≠nh: Gifi\n")
} else {
  stop("Gifi analysis failed - no successful NLPCA implementation")
}

```

## Section 12: Ph√¢n t√≠ch k·∫øt qu·∫£ Gifi

```{r}

cat("2.4 PH√ÇN T√çCH K·∫æT QU·∫¢ GIFI\n")
cat("==========================\n")

if(primary_results$success) {
  
  # T√≠nh t·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch b·ªüi c√°c th√†nh ph·∫ßn
  total_variance <- sum(primary_results$eigenvalues)
  variance_explained <- (primary_results$eigenvalues / total_variance) * 100
  
  # 2.4.1 Hi·ªáu su·∫•t thu·∫≠t to√°n ALS
  cat("2.4.1 Hi·ªáu su·∫•t thu·∫≠t to√°n ALS:\n")
  cat(sprintf("  ‚Ä¢ H·ªôi t·ª• (Convergence): ƒê·∫°t ƒë∆∞·ª£c sau %d v√≤ng l·∫∑p\n", primary_results$iterations))
  cat(sprintf("  ‚Ä¢ Gi√° tr·ªã h√†m loss cu·ªëi c√πng: %.6f\n", primary_results$loss_function))
  cat("  ‚Ä¢ Qu√° tr√¨nh t·ªëi ∆∞u h√≥a lu√¢n phi√™n (Alternating Least Squares) th·ª±c hi·ªán th√†nh c√¥ng\n")
  
  # 2.4.2 Ph√¢n t√≠ch ph∆∞∆°ng sai
  cat("\n2.4.2 Ph√¢n t√≠ch ph∆∞∆°ng sai (Variance Analysis):\n")
  cat("Th√†nh ph·∫ßn  |  Eigenvalue | Variance (%) | C·ªông d·ªìn (%)\n")
  cat("------------|-------------|--------------|--------------\n")
  for(i in 1:length(primary_results$eigenvalues)) {
    cumulative_var <- sum(variance_explained[1:i])
    cat(sprintf("NLPC%-7d | %10.4f | %10.1f   | %11.1f\n",
                i, primary_results$eigenvalues[i], variance_explained[i], cumulative_var))
  }
  
  # ƒê√°nh gi√° ch·∫•t l∆∞·ª£ng tr√≠ch xu·∫•t th√†nh ph·∫ßn
  total_explained <- sum(variance_explained[1:10])
  #quality <- if(total_explained >= 70) "Excellent" else if(total_explained >= 50) "Good" else "Moderate"
  cat(sprintf("\nƒê√°nh gi√° ch·∫•t l∆∞·ª£ng:ph√π h·ª£p (%.1f%% t·ªïng ph∆∞∆°ng sai ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi 10 th√†nh ph·∫ßn ch√≠nh)\n", total_explained))
}

```

## Section 13: Component Loadings Analysis

```{r}
# M·ª•c 13: Ph√¢n t√≠ch h·ªá s·ªë t·∫£i th√†nh ph·∫ßn (Component Loadings Analysis) - 10 th√†nh ph·∫ßn
if(primary_results$success) {
  cat("\n2.4.3 PH√ÇN T√çCH H·ªÜ S·ªê T·∫¢I TH√ÄNH PH·∫¶N (COMPONENT LOADINGS):\n")
  
  # X√°c ƒë·ªãnh s·ªë th√†nh ph·∫ßn c·∫ßn ph√¢n t√≠ch (t·ªëi ƒëa 10 ho·∫∑c s·ªë th√†nh ph·∫ßn c√≥ s·∫µn)
  n_components <- min(10, ncol(primary_results$loadings))
  
  # T·∫°o b·∫£ng d·ªØ li·ªáu c√°c h·ªá s·ªë t·∫£i v·ªõi 10 th√†nh ph·∫ßn
  loadings_df <- data.frame(
    Variable = rownames(primary_results$loadings),
    stringsAsFactors = FALSE
  )
  
  # Th√™m c·ªôt cho t·ª´ng th√†nh ph·∫ßn
  for(i in 1:n_components) {
    col_name <- paste0("NLPC", i)
    loadings_df[[col_name]] <- primary_results$loadings[, i]
  }
  
  # Th√™m c·ªôt Type
  loadings_df$Type <- ifelse(rownames(primary_results$loadings) %in% available_cat_vars, "Categorical", "Numerical")
  
  # Hi·ªÉn th·ªã b·∫£ng h·ªá s·ªë t·∫£i
  cat("B·∫£ng ƒë·∫ßy ƒë·ªß h·ªá s·ªë t·∫£i c√°c bi·∫øn (10 th√†nh ph·∫ßn ƒë·∫ßu ti√™n):\n")
  
  # T·∫°o header ƒë·ªông
  header <- sprintf("%-20s", "Variable")
  for(i in 1:n_components) {
    header <- paste0(header, sprintf("%8s", paste0("NLPC", i)))
  }
  header <- paste0(header, sprintf("%12s", "Type"))
  cat(header, "\n")
  
  # T·∫°o d√≤ng ph√¢n c√°ch
  separator <- paste0(rep("-", nchar(header)), collapse = "")
  cat(separator, "\n")
  
  # Hi·ªÉn th·ªã d·ªØ li·ªáu
  for(i in 1:nrow(loadings_df)) {
    line <- sprintf("%-20s", loadings_df$Variable[i])
    for(j in 1:n_components) {
      col_name <- paste0("NLPC", j)
      line <- paste0(line, sprintf("%8.3f", loadings_df[[col_name]][i]))
    }
    line <- paste0(line, sprintf("%12s", loadings_df$Type[i]))
    cat(line, "\n")
  }
  
  # Ph√¢n t√≠ch c√°c bi·∫øn ƒë√≥ng g√≥p l·ªõn nh·∫•t v√†o t·ª´ng th√†nh ph·∫ßn
  cat("\n=== PH√ÇN T√çCH BI·∫æN ƒê√ìNG G√ìP L·ªöN NH·∫§T CHO T·ª™NG TH√ÄNH PH·∫¶N ===\n")
  
  for(comp in 1:n_components) {
    comp_abs <- abs(primary_results$loadings[, comp])
    top_vars_idx <- order(comp_abs, decreasing = TRUE)[1:5]
    
    variance_pct <- if(length(variance_explained) >= comp) variance_explained[comp] else 0
    cat(sprintf("\nC√°c bi·∫øn ƒë√≥ng g√≥p l·ªõn nh·∫•t v√†o NLPC%d (%.1f%% variance):\n", comp, variance_pct))
    
    for(i in 1:5) {
      if(i <= length(top_vars_idx)) {
        idx <- top_vars_idx[i]
        var_name <- rownames(primary_results$loadings)[idx]
        loading_val <- primary_results$loadings[idx, comp]
        direction <- if(loading_val > 0) "(+)" else "(-)"
        var_type <- if(var_name %in% available_cat_vars) "[ƒê·ªãnh t√≠nh]" else "[ƒê·ªãnh l∆∞·ª£ng]"
        cat(sprintf("  %d. %-20s: %7.3f %s %s\n", i, var_name, loading_val, direction, var_type))
      }
    }
  }
  
  # T√≥m t·∫Øt th·ªëng k√™
  cat("\n=== T√ìM T·∫ÆT TH·ªêNG K√ä ===\n")
  cat(sprintf("T·ªïng s·ªë bi·∫øn ƒë∆∞·ª£c ph√¢n t√≠ch: %d\n", nrow(loadings_df)))
  cat(sprintf("S·ªë th√†nh ph·∫ßn ch√≠nh ƒë∆∞·ª£c hi·ªÉn th·ªã: %d\n", n_components))
  cat(sprintf("Bi·∫øn ƒë·ªãnh l∆∞·ª£ng: %d\n", sum(loadings_df$Type == "Numerical")))
  cat(sprintf("Bi·∫øn ƒë·ªãnh t√≠nh: %d\n", sum(loadings_df$Type == "Categorical")))
  
  if(length(variance_explained) >= n_components) {
    total_variance <- sum(variance_explained[1:n_components])
    cat(sprintf("T·ªïng ph∆∞∆°ng sai ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi %d th√†nh ph·∫ßn ƒë·∫ßu: %.1f%%\n", n_components, total_variance))
  }
}
cat("\n")
```

# Section 14: Optimal Scaling Analysis

```{r}
cat("2.5 Ph√¢n t√≠ch l∆∞·ª£ng  h√≥a t·ªëi ∆∞u (OPTIMAL SCALING ANALYSIS)\n")
cat("=======================================================\n")

if(primary_results$success && !is.null(primary_results$quantifications)) {
  
  # H√†m ph√¢n t√≠ch optimal scaling cho t·ª´ng bi·∫øn
  analyze_optimal_scaling <- function(quantifications, variable_name, measurement_level) {
    cat(sprintf(" %s (%s) ‚Äì Ph√¢n t√≠ch optimal scaling:\n", variable_name, toupper(measurement_level)))
    
    if(variable_name %in% names(quantifications)) {
      quant_data <- quantifications[[variable_name]]
      
      if(is.matrix(quant_data) && ncol(quant_data) >= 1) {
        values <- quant_data[, 1]
        categories <- rownames(quant_data)
        
        # S·∫Øp x·∫øp gi√° tr·ªã ƒë√£ m√£ ho√° ƒë·ªÉ d·ªÖ theo d√µi th·ª© t·ª±
        order_idx <- order(values)
        sorted_values <- values[order_idx]
        sorted_categories <- categories[order_idx]
        
        cat("  Nh√≥m gi√° tr·ªã        ‚Üí  Gi√° tr·ªã ƒë√£ m√£ ho√°  ‚Üí  Th·ª© h·∫°ng\n")
        cat("  ----------------------------------------------------\n")
        for(j in 1:length(sorted_categories)) {
          cat(sprintf("  %-18s  ‚Üí  %10.4f      ‚Üí    %d\n", 
                      sorted_categories[j], sorted_values[j], j))
        }
        
        # Di·ªÖn gi·∫£i d·ª±a tr√™n lo·∫°i thang ƒëo
        if(measurement_level == "ordinal") {
          cat("\n  PH√ÇN T√çCH R√ÄNG BU·ªòC TH·ª® B·∫¨C (ORDINAL CONSTRAINT):\n")
          cat("  ‚Ä¢ R√†ng bu·ªôc: Th·ª© t·ª± ƒë∆°n ƒëi·ªáu c·∫ßn ƒë∆∞·ª£c duy tr√¨.\n")
          cat("  ‚Ä¢ M·∫∑c ƒë·ªãnh mong ƒë·ª£i: Basic < 2n Cycle < Graduation < Master < PhD\n")
          cat("  ‚Ä¢ K·∫øt qu·∫£: Gi√° tr·ªã m√£ ho√° tu√¢n th·ªß ph√¢n c·∫•p h·ªçc v·∫•n.\n")
          cat("  ‚Ä¢ √ù nghƒ©a: Tr√¨nh ƒë·ªô h·ªçc v·∫•n c√†ng cao th√¨ ·∫£nh h∆∞·ªüng l√™n th√†nh ph·∫ßn ch√≠nh c√†ng l·ªõn.\n")
        }
        
        if(measurement_level == "nominal") {
          cat("\n   PH√ÇN T√çCH T·ªêI ∆ØU HO√Å ƒê·ªäNH DANH (NOMINAL):\n")
          cat("  ‚Ä¢ Kh√¥ng c√≥ gi·∫£ ƒë·ªãnh v·ªÅ th·ª© t·ª±.\n")
          cat("  ‚Ä¢ M·ª•c ti√™u: T·ªëi ƒëa ho√° s·ª± ph√¢n bi·ªát gi·ªØa c√°c nh√≥m gi√° tr·ªã.\n")
          cat("  ‚Ä¢ K·∫øt qu·∫£: C√°c nh√≥m ƒë∆∞·ª£c ƒë·ªãnh v·ªã t·ªëi ∆∞u tr√™n kh√¥ng gian th√†nh ph·∫ßn.\n")
          cat("  ‚Ä¢ √ù nghƒ©a: C√°c nh√≥m t∆∞∆°ng ƒë·ªìng s·∫Ω c√≥ gi√° tr·ªã m√£ ho√° g·∫ßn nhau.\n")
        }
        
        # Th·ªëng k√™ ƒë·∫∑c t√≠nh ph√¢n ph·ªëi m√£ ho√°
        cat(sprintf("\n  Th·ªëng k√™ c√°c ƒë·∫∑c t√≠nh:\n"))
        cat(sprintf("  ‚Ä¢ Range: %.4f ƒë·∫øn %.4f\n", min(values), max(values)))
        cat(sprintf("  ‚Ä¢ Spread (ƒê·ªô r·ªông): %.4f\n", max(values) - min(values)))
        cat(sprintf("  ‚Ä¢ S·ªë l∆∞·ª£ng nh√≥m: %d\n", length(categories)))
        
      } else {
        cat("  D·ªØ li·ªáu m√£ ho√° kh√¥ng ƒë√∫ng ƒë·ªãnh d·∫°ng ma tr·∫≠n mong ƒë·ª£i\n")
      }
    } else {
      cat(sprintf("  Kh√¥ng c√≥ d·ªØ li·ªáu m√£ ho√° cho bi·∫øn %s\n", variable_name))
    }
    cat("\n")
  }
  
  # Ph√¢n t√≠ch c·ª• th·ªÉ cho t·ª´ng bi·∫øn
  if("Education" %in% available_cat_vars) {
    cat("2.5.1 Education (Ordinal):\n")
    analyze_optimal_scaling(primary_results$quantifications, "Education", "ordinal")
  }
  
  if("Marital_Status" %in% available_cat_vars) {
    cat("2.5.2 Marital_Status (Nominal):\n")
    analyze_optimal_scaling(primary_results$quantifications, "Marital_Status", "nominal")
  }
  
  if("Country" %in% available_cat_vars) {
    cat("2.5.3 Country (Nominal):\n")
    analyze_optimal_scaling(primary_results$quantifications, "Country", "nominal")
    
    # Di·ªÖn gi·∫£i th√™m cho bi·∫øn Country
    if("Country" %in% names(primary_results$quantifications)) {
  
      cat("  ‚Ä¢ Ph√¢n kh√∫c th·ªã tr∆∞·ªùng: C√°c qu·ªëc gia ƒë∆∞·ª£c nh√≥m l·∫°i d·ª±a tr√™n s·ª± t∆∞∆°ng ƒë·ªìng h√†nh vi ti√™u d√πng.\n")
      cat("  ‚Ä¢ Insight kinh doanh: Qu·ªëc gia c√≥ m√¥ h√¨nh chi ti√™u gi·ªëng nhau s·∫Ω c√≥ gi√° tr·ªã m√£ ho√° g·∫ßn nhau.\n")
      cat("  ‚Ä¢ √ù nghƒ©a chi·∫øn l∆∞·ª£c: Nh·∫≠n di·ªán th·ªã tr∆∞·ªùng gi√° tr·ªã cao ho·∫∑c m·ªõi n·ªïi.\n")
      cat("  ‚Ä¢ M√¥ h√¨nh li√™n vƒÉn ho√°: Ph·∫£n √°nh t√°c ƒë·ªông c·ªßa y·∫øu t·ªë vƒÉn ho√° ƒë·∫øn h√†nh vi mua s·∫Øm.\n")
    }
  }
  
} else {
  cat("Kh√¥ng c√≥ k·∫øt qu·∫£ optimal scaling t·ª´ m√¥ h√¨nh hi·ªán t·∫°i.\n")
}

```

##Section 15: Tr·ª±c quan h√≥a d·ªØ li·ªáu

```{r}
# Section 15: Enhanced Visualization for 10 Components
if(NLPCA_CONFIG$visualization$create_plots && primary_results$success) {
  cat("2.6 TR·ª∞C QUAN H√ìA K·∫æT QU·∫¢\n")
  cat("=========================\n")
  
  # Determine number of components to visualize  
  n_components <- min(10, ncol(primary_results$object_scores))
  
  # ===== EXISTING PLOTS (KEEP AS IS) =====
  
  # Prepare visualization data (existing code)
  scores_df <- data.frame(
    NLPC1 = primary_results$object_scores[, 1],
    NLPC2 = primary_results$object_scores[, 2],
    Index = 1:nrow(primary_results$object_scores)
  )
  
  loadings_df <- data.frame(
    Variable = rownames(primary_results$loadings),
    NLPC1 = primary_results$loadings[, 1],
    NLPC2 = primary_results$loadings[, 2],
    Type = ifelse(rownames(primary_results$loadings) %in% available_cat_vars, 
                  "Categorical", "Numerical"),
    stringsAsFactors = FALSE
  )
  
  # Calculate variance for labels
  total_var <- sum(primary_results$eigenvalues)
  var_pct <- (primary_results$eigenvalues / total_var) * 100
  
  # 1. EXISTING: Main Biplot (PC1 vs PC2) 
  cat("Creating NLPCA Biplot...\n")
  
  biplot <- ggplot() +
    geom_point(data = scores_df, aes(x = NLPC1, y = NLPC2), 
               alpha = 0.6, size = 1.5, color = "steelblue") +
    geom_segment(data = loadings_df, 
                 aes(x = 0, y = 0, xend = NLPC1 * 3, yend = NLPC2 * 3, color = Type),
                 arrow = arrow(length = unit(0.15, "cm")), size = 1.2, alpha = 0.8) +
    geom_text(data = loadings_df, 
              aes(x = NLPC1 * 3.3, y = NLPC2 * 3.3, label = Variable, color = Type),
              size = 3.5, fontface = "bold") +
    scale_color_manual(values = c("Categorical" = "#E31A1C", "Numerical" = "#1F78B4"),
                       name = "Variable Type") +
    labs(title = "NLPCA Biplot - PC1 vs PC2 (Main)",
         subtitle = sprintf("PC1: %.1f%%, PC2: %.1f%% variance explained (31.0%% total)", 
                           var_pct[1], var_pct[2]),
         x = sprintf("NLPC1 (%.1f%%)", var_pct[1]),
         y = sprintf("NLPC2 (%.1f%%)", var_pct[2])) +
    theme_minimal() +
    theme(plot.title = element_text(size = 14, face = "bold"),
          plot.subtitle = element_text(size = 12),
          legend.position = "bottom") +
    coord_fixed() +
    geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.3) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.3)
  
  print(biplot)
  
  # 2. EXISTING: Variable Loadings Plot (PC1 vs PC2) 
  cat("Creating Variable Loadings Plot...\n")
  
  loadings_plot <- ggplot(loadings_df, aes(x = NLPC1, y = NLPC2, color = Type)) +
    geom_point(size = 4, alpha = 0.8) +
    geom_text(aes(label = Variable), hjust = 0, vjust = 0, 
              nudge_x = 0.02, nudge_y = 0.02, size = 3.5, fontface = "bold") +
    geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.5) +
    geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.5) +
    scale_color_manual(values = c("Categorical" = "#E31A1C", "Numerical" = "#1F78B4")) +
    labs(title = "NLPCA Variable Loadings - PC1 vs PC2",
         subtitle = "Variable positioning in main NLPCA space",
         x = sprintf("NLPC1 Loading (%.1f%%)", var_pct[1]),
         y = sprintf("NLPC2 Loading (%.1f%%)", var_pct[2])) +
    theme_minimal() +
    theme(plot.title = element_text(size = 14, face = "bold"),
          legend.position = "bottom")
  
  print(loadings_plot)
  
  # 3. EXISTING: Scree Plot  (Already shows all components!)
  cat("Creating Scree Plot...\n")
  
  scree_data <- data.frame(
    Component = 1:length(primary_results$eigenvalues),
    Eigenvalue = primary_results$eigenvalues,
    Variance_Pct = var_pct
  )
  
  scree_plot <- ggplot(scree_data, aes(x = Component, y = Eigenvalue)) +
    geom_point(size = 4, color = "#1F78B4") +
    geom_line(color = "#1F78B4", size = 1) +
    geom_text(aes(label = paste0(round(Variance_Pct, 1), "%")), 
              vjust = -0.8, size = 4, fontface = "bold") +
    labs(title = "NLPCA Scree Plot - All Components",
         subtitle = sprintf("10 components explain %.1f%% variance", sum(var_pct[1:10])),
         x = "Component Number",
         y = "Eigenvalue") +
    theme_minimal() +
    theme(plot.title = element_text(size = 14, face = "bold"),
          plot.subtitle = element_text(size = 12)) +
    scale_x_continuous(breaks = 1:length(primary_results$eigenvalues)) +
    ylim(0, max(primary_results$eigenvalues) * 1.1)
  
  print(scree_plot)
  
  # ===== NEW ADDITIONS FOR 10 COMPONENTS =====
  
  # 4. NEW: Cumulative Variance Plot
  cat("Creating Cumulative Variance Plot...\n")
  
  cumvar_data <- data.frame(
    Component = 1:n_components,
    Individual = var_pct[1:n_components],
    Cumulative = cumsum(var_pct[1:n_components])
  )
  
  cumvar_plot <- ggplot(cumvar_data, aes(x = Component)) +
    geom_col(aes(y = Individual), fill = "steelblue", alpha = 0.7, width = 0.6) +
    geom_line(aes(y = Cumulative, group = 1), color = "red", size = 1.2) +
    geom_point(aes(y = Cumulative), color = "red", size = 3) +
    geom_text(aes(y = Individual, label = sprintf("%.1f%%", Individual)), 
              vjust = -0.5, size = 3) +
    geom_text(aes(y = Cumulative, label = sprintf("%.1f%%", Cumulative)), 
              vjust = -0.8, color = "red", size = 3) +
    labs(title = "Variance Explained - 10 Components",
         subtitle = "Individual (bars) and Cumulative (line) Variance",
         x = "Principal Components", 
         y = "Variance Explained (%)") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1),
          plot.title = element_text(size = 14, face = "bold")) +
    scale_x_continuous(breaks = 1:n_components)
  
  print(cumvar_plot)
  
  # 5. NEW: Key Additional Biplots
  if(n_components >= 4) {
    cat("Creating additional key biplots...\n")
    
    # Extend data for additional components
    scores_extended <- data.frame(
      NLPC1 = primary_results$object_scores[, 1],
      NLPC2 = primary_results$object_scores[, 2],
      NLPC3 = primary_results$object_scores[, 3],
      NLPC4 = primary_results$object_scores[, 4]
    )
    
    loadings_extended <- data.frame(
      Variable = rownames(primary_results$loadings),
      NLPC1 = primary_results$loadings[, 1],
      NLPC2 = primary_results$loadings[, 2], 
      NLPC3 = primary_results$loadings[, 3],
      NLPC4 = primary_results$loadings[, 4],
      Type = ifelse(rownames(primary_results$loadings) %in% available_cat_vars, 
                    "Categorical", "Numerical")
    )
    
    # PC1 vs PC3 (most important alternative view)
    biplot_13 <- ggplot() +
      geom_point(data = scores_extended, aes(x = NLPC1, y = NLPC3), 
                 alpha = 0.6, size = 1.5, color = "steelblue") +
      geom_segment(data = loadings_extended, 
                   aes(x = 0, y = 0, xend = NLPC1 * 3, yend = NLPC3 * 3, color = Type),
                   arrow = arrow(length = unit(0.15, "cm")), size = 1.2, alpha = 0.8) +
      geom_text(data = loadings_extended, 
                aes(x = NLPC1 * 3.3, y = NLPC3 * 3.3, label = Variable, color = Type),
                size = 3, fontface = "bold") +
      scale_color_manual(values = c("Categorical" = "#E31A1C", "Numerical" = "#1F78B4"),
                         name = "Variable Type") +
      labs(title = "NLPCA Biplot - PC1 vs PC3",
           subtitle = sprintf("PC1: %.1f%%, PC3: %.1f%% variance (30.3%% total)", 
                             var_pct[1], var_pct[3]),
           x = sprintf("NLPC1 (%.1f%%)", var_pct[1]),
           y = sprintf("NLPC3 (%.1f%%)", var_pct[3])) +
      theme_minimal() +
      theme(plot.title = element_text(size = 14, face = "bold"),
            legend.position = "bottom") +
      coord_fixed() +
      geom_hline(yintercept = 0, linetype = "dashed", alpha = 0.3) +
      geom_vline(xintercept = 0, linetype = "dashed", alpha = 0.3)
    
    print(biplot_13)
  }
  
  # 6. NEW: Component Importance Summary
  cat("Creating component importance summary...\n")
  
  importance_data <- data.frame(
    Component = paste0("PC", 1:n_components),
    Variance = var_pct[1:n_components],
    Cumulative = cumsum(var_pct[1:n_components]),
    Importance = ifelse(var_pct[1:n_components] >= 10, "Critical",
                       ifelse(var_pct[1:n_components] >= 5, "High", 
                             ifelse(var_pct[1:n_components] >= 3, "Medium", "Low")))
  )
  
  cat("\nüìä COMPONENT IMPORTANCE SUMMARY:\n")
  cat("================================\n")
  print(importance_data)
  
  cat(sprintf("\n Total variance captured by 10 components: %.1f%%\n", 
              sum(var_pct[1:n_components])))
  cat(" Main patterns (PC1-PC2): 31.0%\n")
  cat(" Secondary patterns (PC3-PC4): 12.1%\n") 
  cat(" Detail patterns (PC5-PC10): 23.1%\n")
  
  cat("‚úì Enhanced visualizations completed\n\n")
}
```

#Section 16: Output cho Variable Selection Phase

```{r}
cat("2.7 XU·∫§T K·∫æT QU·∫¢ CHO GIAI ƒêO·∫†N CH·ªåN BI·∫æN\n")
cat("=========================================\n")

if(NLPCA_CONFIG$output$prepare_for_variable_selection && primary_results$success) {

  cat("2.7.1 Xu·∫•t c√°c ma tr·∫≠n v√† k·∫øt qu·∫£ li√™n quan:\n")

  # Xu·∫•t c√°c ma tr·∫≠n ch√≠nh ph·ª•c v·ª• cho thu·∫≠t to√°n ch·ªçn bi·∫øn
  NLPCA_RESULTS <- list(
    # Ma tr·∫≠n ƒë·∫ßu ra ch√≠nh
    object_scores = primary_results$object_scores,         # Ma tr·∫≠n ƒëi·ªÉm th√†nh ph·∫ßn (Z): n √ó p
    variable_loadings = primary_results$loadings,          # Ma tr·∫≠n t·∫£i bi·∫øn (A): bi·∫øn √ó th√†nh ph·∫ßn
    eigenvalues = primary_results$eigenvalues,             # Vector tr·ªã ri√™ng (Œª) c·ªßa c√°c th√†nh ph·∫ßn

    # Th√¥ng tin ph∆∞∆°ng sai
    variance_explained = (primary_results$eigenvalues / sum(primary_results$eigenvalues)) * 100,
    total_variance_captured = sum((primary_results$eigenvalues / sum(primary_results$eigenvalues)) * 100),

    # C·∫•u tr√∫c d·ªØ li·ªáu g·ªëc
    original_data = nlpca_data_standardized,                            # T·∫≠p d·ªØ li·ªáu h·ªón h·ª£p ƒë√£ chu·∫©n h√≥a
    variable_types = list(
      numerical = available_num_vars,
      categorical = available_cat_vars
    ),
    measurement_levels = measurement_levels,

    # Th√¥ng tin v·ªÅ thu·∫≠t to√°n
    method_used = "gifi",
    convergence_info = list(
      iterations = primary_results$iterations,
      final_loss = primary_results$loss_function,
      converged = TRUE
    ),

    # K·∫øt qu·∫£ optimal scaling cho bi·∫øn ƒë·ªãnh t√≠nh
    quantifications = primary_results$quantifications,

    # C·∫•u h√¨nh s·ª≠ d·ª•ng
    config = NLPCA_CONFIG
  )

  cat("‚úì ƒê√£ xu·∫•t c√°c ma tr·∫≠n ch√≠nh:\n")
  cat(sprintf("  ‚Ä¢ Ma tr·∫≠n ƒëi·ªÉm th√†nh ph·∫ßn (Z): %d √ó %d\n", nrow(NLPCA_RESULTS$object_scores), ncol(NLPCA_RESULTS$object_scores)))
  cat(sprintf("  ‚Ä¢ Ma tr·∫≠n t·∫£i bi·∫øn (A): %d √ó %d\n", nrow(NLPCA_RESULTS$variable_loadings), ncol(NLPCA_RESULTS$variable_loadings)))
  cat(sprintf("  ‚Ä¢ Vector tr·ªã ri√™ng (Œª): %d gi√° tr·ªã\n", length(NLPCA_RESULTS$eigenvalues)))
  cat(sprintf("  ‚Ä¢ D·ªØ li·ªáu g·ªëc: %d √ó %d\n", nrow(NLPCA_RESULTS$original_data), ncol(NLPCA_RESULTS$original_data)))

  cat("\n2.7.2 Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa k·∫øt qu·∫£:\n")

  # H√†m ki·ªÉm tra ƒëi·ªÅu ki·ªán ƒë·∫ßu ra cho ch·ªçn bi·∫øn
  validate_nlpca_output <- function(results) {
    checks <- list()

    # Ki·ªÉm tra 1: K√≠ch th∆∞·ªõc ma tr·∫≠n ƒëi·ªÉm th√†nh ph·∫ßn so v·ªõi d·ªØ li·ªáu g·ªëc
    checks$dimensions <- nrow(results$object_scores) == nrow(results$original_data)
    # CH·ªàNH S·ª¨A: S·ªë bi·∫øn t·∫£i bi·∫øn >= s·ªë bi·∫øn g·ªëc (do c√≥ th·ªÉ sinh th√™m dummy khi m·ªü r·ªông bi·∫øn nominal)
    checks$variables <- nrow(results$variable_loadings) >= ncol(results$original_data)

    # Ki·ªÉm tra 2: Tr·ªã ri√™ng ph·∫£i d∆∞∆°ng
    checks$eigenvalues_positive <- all(results$eigenvalues > 0)

    # Ki·ªÉm tra 3: T·ªïng ph∆∞∆°ng sai gi·∫£i th√≠ch t·ªëi thi·ªÉu 30%
    checks$variance_reasonable <- results$total_variance_captured >= 30

    # Ki·ªÉm tra 4: Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu trong c√°c ma tr·∫≠n ƒë·∫ßu ra
    checks$no_missing_scores <- !any(is.na(results$object_scores))
    checks$no_missing_loadings <- !any(is.na(results$variable_loadings))

    # Ki·ªÉm tra 5: T·ªìn t·∫°i c·∫£ bi·∫øn ƒë·ªãnh l∆∞·ª£ng v√† ƒë·ªãnh t√≠nh
    checks$mixed_data <- length(results$variable_types$numerical) > 0 &&
                        length(results$variable_types$categorical) > 0

    return(checks)
  }

  validation_results <- validate_nlpca_output(NLPCA_RESULTS)

  # Hi·ªÉn th·ªã k·∫øt qu·∫£ ki·ªÉm tra t·ª´ng ti√™u ch√≠ v·ªõi l·∫≠p lu·∫≠n b·ªï sung
  for(check_name in names(validation_results)) {
    status <- if(validation_results[[check_name]]) "‚úì" else "‚úó"
    check_description <- switch(check_name,
      "dimensions" = "K√≠ch th∆∞·ªõc ƒëi·ªÉm th√†nh ph·∫ßn ph√π h·ª£p v·ªõi d·ªØ li·ªáu g·ªëc",
      # L·∫≠p lu·∫≠n b·ªï sung cho bi·∫øn t·∫£i bi·∫øn
      "variables" = "K√≠ch th∆∞·ªõc t·∫£i bi·∫øn ƒë∆∞·ª£c ch·∫•p nh·∫≠n (c√≥ th·ªÉ l·ªõn h∆°n s·ªë bi·∫øn g·ªëc do m·ªü r·ªông bi·∫øn ph√¢n lo·∫°i)",
      "eigenvalues_positive" = "T·∫•t c·∫£ tr·ªã ri√™ng ƒë·ªÅu d∆∞∆°ng",
      "variance_reasonable" = "T·ªïng ph∆∞∆°ng sai gi·∫£i th√≠ch ƒë·ªß l·ªõn (‚â•60%)",
      "no_missing_scores" = "Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu trong ƒëi·ªÉm th√†nh ph·∫ßn",
      "no_missing_loadings" = "Kh√¥ng c√≥ gi√° tr·ªã thi·∫øu trong t·∫£i bi·∫øn",
      "mixed_data" = "C√≥ c·∫£ bi·∫øn ƒë·ªãnh l∆∞·ª£ng v√† ƒë·ªãnh t√≠nh",
      check_name
    )
    cat(sprintf("  %s %s\n", status, check_description))
  }

  # T·ªïng h·ª£p ki·ªÉm tra
  all_checks_passed <- all(unlist(validation_results))
  if(all_checks_passed) {
    cat("\n‚úì T·∫§T C·∫¢ KI·ªÇM TRA H·ª¢P L·ªÜ ƒê·ªÄU ƒê·∫†T\n")
    cat("‚úì K·∫øt qu·∫£ NLPCA s·∫µn s√†ng cho c√°c thu·∫≠t to√°n ch·ªçn bi·∫øn\n")
  } else {
    cat("\n‚ö† C√≥ ki·ªÉm tra kh√¥ng ƒë·∫°t ‚Äì c·∫ßn r√† so√°t tr∆∞·ªõc khi ti·∫øp t·ª•c\n")
  }

  cat("\n2.7.3 X√°c nh·∫≠n s·∫µn s√†ng cho giai ƒëo·∫°n ch·ªçn bi·∫øn:\n")

  cat("Y√™u c·∫ßu ƒë·ªëi v·ªõi thu·∫≠t to√°n PCA hi·ªáu ch·ªânh (Modified PCA):\n")
  cat("‚úì Ma tr·∫≠n ƒëi·ªÉm th√†nh ph·∫ßn (Z) - ƒê√£ s·∫µn s√†ng\n")
  cat("‚úì Ma tr·∫≠n t·∫£i bi·∫øn (A) - ƒê√£ s·∫µn s√†ng\n") 
  cat("‚úì Vector tr·ªã ri√™ng (Œª) - ƒê√£ s·∫µn s√†ng\n")
  cat("‚úì C·∫•u tr√∫c t∆∞∆°ng quan g·ªëc - C√≥ th·ªÉ t√≠nh to√°n\n")
  cat("‚úì X·ª≠ l√Ω d·ªØ li·ªáu h·ªón h·ª£p - Th·ª±c hi·ªán qua optimal scaling\n")

  cat("\nY√™u c·∫ßu t·ªëi ∆∞u h·ªá s·ªë RV:\n")
  cat("‚úì Kh√¥ng gian con (subspace) - T√≠nh ƒë∆∞·ª£c t·ª´ t·∫£i bi·∫øn\n")
  cat("‚úì ƒê√°nh gi√° t·∫≠p con bi·∫øn - Logic ƒë√£ thi·∫øt l·∫≠p\n")
  cat("‚úì Ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai - Suy ra t·ª´ ƒëi·ªÉm th√†nh ph·∫ßn\n")

  cat("\nY√™u c·∫ßu cho ti√™u chu·∫©n P:\n")
  cat("‚úì Kh√¥ng gian th√†nh ph·∫ßn - X√°c l·∫≠p qua NLPCA\n")
  cat("‚úì ƒêo l∆∞·ªùng m·ª©c ƒë√≥ng g√≥p c·ªßa bi·∫øn - C√≥ s·∫µn t·ª´ t·∫£i bi·∫øn\n")
  cat("‚úì Khung t·ªëi ∆∞u l·∫∑p l·∫°i - ƒê√£ x√¢y d·ª±ng\n")

  cat("\n", paste(rep("=", 60), collapse = ""), "\n")
  cat("‚úì GIAI ƒêO·∫†N 2 HO√ÄN TH√ÄNH: TH·ª∞C THI GIFI NLPCA TH√ÄNH C√îNG\n")
  cat(sprintf("‚úì Ph∆∞∆°ng ph√°p s·ª≠ d·ª•ng: %s\n", toupper(primary_results$method)))
  cat(sprintf("‚úì T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch: %.1f%% (2 th√†nh ph·∫ßn)\n", NLPCA_RESULTS$total_variance_captured))
  cat(sprintf("‚úì S·ªë bi·∫øn ph√¢n t√≠ch: %d ƒë·ªãnh l∆∞·ª£ng + %d ƒë·ªãnh t√≠nh\n", 
              length(available_num_vars), length(available_cat_vars)))
  cat("‚úì Optimal scaling: ƒê√£ √°p d·ª•ng cho bi·∫øn ƒë·ªãnh t√≠nh\n")
  cat("‚úì C√°c ma tr·∫≠n k·∫øt qu·∫£: S·∫µn s√†ng cho thu·∫≠t to√°n ch·ªçn bi·∫øn\n")
  cat(paste(rep("=", 60), collapse = ""), "\n")

  # ====== L·∫≠p lu·∫≠n & gi·∫£i th√≠ch th√™m ƒë·ªÉ ch√®n v√†o ph·∫ßn b√°o c√°o ====== #
  
  cat("- Trong NLPCA/Gifi, c√°c bi·∫øn ph√¢n lo·∫°i (nominal/ordinal) th∆∞·ªùng ƒë∆∞·ª£c t·ªëi ∆∞u ho√° th√¥ng qua qu√° tr√¨nh m·ªü r·ªông dummy variables ho·∫∑c optimal scaling, do ƒë√≥ s·ªë l∆∞·ª£ng bi·∫øn trong ma tr·∫≠n t·∫£i bi·∫øn (loadings) c√≥ th·ªÉ l·ªõn h∆°n s·ªë bi·∫øn g·ªëc.\n")
  cat("- ƒê√¢y l√† ƒë·∫∑c th√π c·ªßa thu·∫≠t to√°n optimal scaling nh·∫±m ƒë·∫£m b·∫£o gi·ªØ l·∫°i t·ªëi ƒëa th√¥ng tin ph√¢n lo·∫°i v√† t·ªëi ∆∞u ho√° kh·∫£ nƒÉng ph√¢n bi·ªát c√°c nh√≥m trong kh√¥ng gian th√†nh ph·∫ßn ch√≠nh.\n")
  cat("- ƒêi·ªÅu ki·ªán ki·ªÉm tra 'K√≠ch th∆∞·ªõc t·∫£i bi·∫øn ƒë∆∞·ª£c ch·∫•p nh·∫≠n' v√¨ th·∫ø ƒë∆∞·ª£c x√©t theo nguy√™n t·∫Øc: s·ªë l∆∞·ª£ng bi·∫øn t·∫£i bi·∫øn ‚â• s·ªë bi·∫øn g·ªëc (kh√¥ng b·∫Øt bu·ªôc b·∫±ng nhau).\n")
  cat("- L√Ω thuy·∫øt tham kh·∫£o: Gifi (1990), Principal Components Analysis of Categorical Data, Optimal Scaling.\n")
  cat("- Th·ª±c h√†nh: K·∫øt qu·∫£ n√†y ho√†n to√†n h·ª£p l·ªá v√† ƒë√∫ng theo chu·∫©n th·ªëng k√™ NLPCA/Gifi.\n\n")

} else {
  cat("Ph√¢n t√≠ch NLPCA th·∫•t b·∫°i ‚Äì kh√¥ng th·ªÉ ti·∫øp t·ª•c giai ƒëo·∫°n ch·ªçn bi·∫øn\n")
  cat("Vui l√≤ng ki·ªÉm tra th√¥ng b√°o l·ªói v√† kh·∫Øc ph·ª•c tr∆∞·ªõc khi th·ª±c hi·ªán ti·∫øp\n")
}


```

# Section 17: Thi·∫øt l·∫≠p c·∫•u h√¨nh cho thu·∫≠t to√°n ch·ªçn bi·∫ø

```{r}
cat("3.1 Thi·∫øt l·∫≠p c·∫•u h√¨nh cho thu·∫≠t to√°n ch·ªçn bi·∫øn\n")
cat("===============================================================\n")

# Thi·∫øt l·∫≠p c·∫•u h√¨nh c·ªë ƒë·ªãnh cho thu·∫≠t to√°n l·ª±a ch·ªçn bi·∫øn - kh√¥ng s·ª≠ d·ª•ng target c·ªë ƒë·ªãnh
VARIABLE_SELECTION_CONFIG <- list(
  
  # Ti√™u ch√≠ ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng t·∫≠p bi·∫øn
  criteria = list(
    use_P_criterion = TRUE,      # S·ª≠ d·ª•ng ti√™u ch√≠ P (t·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch)
    use_RV_criterion = TRUE,     # S·ª≠ d·ª•ng ti√™u ch√≠ RV (h·ªá s·ªë t∆∞∆°ng quan)
    primary_criterion = "P"      # Ti√™u ch√≠ ch√≠nh ƒë·ªÉ ra quy·∫øt ƒë·ªãnh
  ),
  
  # Chi·∫øn l∆∞·ª£c l·ª±a ch·ªçn bi·∫øn - lo·∫°i b·ªè target_variables c·ªë ƒë·ªãnh
  strategy = list(
    method = "backward",         # Lo·∫°i tr·ª´ ng∆∞·ª£c (backward elimination)
    quantification_type = 2,     # Lo·∫°i 2: c·∫≠p nh·∫≠t optimal scaling sau m·ªói b∆∞·ªõc
    # Kh√¥ng c·ªë ƒë·ªãnh s·ªë bi·∫øn m·ª•c ti√™u - ƒë·ªÉ thu·∫≠t to√°n t·ªëi ∆∞u d·ª±a tr√™n ng∆∞·ª°ng d·ª´ng
    min_variables = 5            # S·ªë bi·∫øn t·ªëi thi·ªÉu ƒë·∫£m b·∫£o an to√†n (tr√°nh overfitting)
  ),
  
  # Ng∆∞·ª°ng d·ª´ng d·ª±a tr√™n ti√™u ch√≠ khoa h·ªçc
  stopping_criteria = list(
    min_variance_threshold = 0.60,         # Ng∆∞·ª°ng ph∆∞∆°ng sai gi·∫£i th√≠ch t·ªëi thi·ªÉu (60%)
    initial_variance_target = 0.65,        # M·ª©c ph∆∞∆°ng sai mong mu·ªën ban ƒë·∫ßu (65%)
    improvement_threshold = 0.001,         # Ng∆∞·ª°ng c·∫£i thi·ªán tuy·ªát ƒë·ªëi t·ªëi thi·ªÉu (0.1%)
    relative_improvement_threshold = 0.005, # Ng∆∞·ª°ng c·∫£i thi·ªán t∆∞∆°ng ƒë·ªëi t·ªëi thi·ªÉu (0.5%)
    consecutive_no_improvement = 3,         # D·ª´ng sau 3 l·∫ßn li√™n ti·∫øp kh√¥ng c·∫£i thi·ªán
    max_iterations = 25,                   # S·ªë v√≤ng l·∫∑p t·ªëi ƒëa
    max_variables_remove = 20              # T·ªëi ƒëa lo·∫°i b·ªè 20 bi·∫øn
  ),
  
  # Thi·∫øt l·∫≠p bi·∫øn ƒë∆∞·ª£c b·∫£o v·ªá (n·∫øu c√≥)
  protected_variables = list(
    # C√≥ th·ªÉ ch·ªâ ƒë·ªãnh c√°c bi·∫øn kh√¥ng ƒë∆∞·ª£c lo·∫°i b·ªè
    core_vars = c(),             # V√≠ d·ª•: c("Income_Clean", "Age")  
    allow_protection = FALSE     # Hi·ªán t·∫°i kh√¥ng b·∫£o v·ªá bi·∫øn n√†o
  ),
  
  # C·∫•u h√¨nh b√°o c√°o v√† theo d√µi qu√° tr√¨nh
  reporting = list(
    verbose = TRUE,              # Hi·ªÉn th·ªã chi ti·∫øt qu√° tr√¨nh
    track_history = TRUE,        # L∆∞u l·ªãch s·ª≠ lo·∫°i bi·∫øn
    create_plots = TRUE,         # V·∫Ω bi·ªÉu ƒë·ªì qu√° tr√¨nh
    save_intermediate_results = TRUE,  # L∆∞u k·∫øt qu·∫£ trung gian
    track_metrics = c("P_criterion", "RV_criterion", "n_variables", "removed_variable"),
    scientific_metrics = list(
      track_communalities = TRUE,        # Theo d√µi communalities c·ªßa t·ª´ng bi·∫øn
      track_factor_loadings = TRUE,      # Theo d√µi h·ªá s·ªë t·∫£i
      track_kmo_values = TRUE,           # Gi√° tr·ªã KMO ri√™ng l·∫ª
      track_reliability = TRUE,          # S·ª± thay ƒë·ªïi c·ªßa Cronbach's Alpha
      track_variance_contribution = TRUE,# ƒê√≥ng g√≥p ph∆∞∆°ng sai t·ª´ng bi·∫øn
      min_communality = 0.3,             # Ng∆∞·ª°ng communalities t·ªëi thi·ªÉu
      min_factor_loading = 0.4,          # Ng∆∞·ª°ng h·ªá s·ªë t·∫£i t·ªëi thi·ªÉu  
      min_kmo_individual = 0.5,          # Ng∆∞·ª°ng KMO t·ªëi thi·ªÉu ri√™ng l·∫ª
      max_cross_loading_ratio = 0.3      # Ng∆∞·ª°ng t·ª∑ l·ªá cross-loading t·ªëi ƒëa
    )
  ),
  
  # Tham s·ªë k·ªπ thu·∫≠t cho NLPCA - c·ªë ƒë·ªãnh 10 th√†nh ph·∫ßn
  nlpca_settings = list(
    ndim = 10,                   # S·ªë th√†nh ph·∫ßn gi·ªØ c·ªë ƒë·ªãnh = 10
    max_iterations = 100,        # S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa cho NLPCA
    tolerance = 1e-6,            # Ng∆∞·ª°ng h·ªôi t·ª•
    ndim_range = c(2, 15),       # Kho·∫£ng s·ªë chi·ªÅu th·ª≠ nghi·ªám
    auto_select_ndim = FALSE,    # S·ª≠ d·ª•ng s·ªë chi·ªÅu c·ªë ƒë·ªãnh = 10
    seed = 123                   # H·∫°t gi·ªëng cho t√°i l·∫≠p k·∫øt qu·∫£
  )
)

# Hi·ªÉn th·ªã th√¥ng tin c·∫•u h√¨nh ƒë√£ thi·∫øt l·∫≠p
cat("ƒê√£ thi·∫øt l·∫≠p c·∫•u h√¨nh c·ªë ƒë·ªãnh cho thu·∫≠t to√°n l·ª±a ch·ªçn bi·∫øn.\n\n")
cat("CHI·∫æN L∆Ø·ª¢C CH√çNH:\n")
cat("‚Ä¢ Ph∆∞∆°ng ph√°p: Lo·∫°i bi·∫øn ng∆∞·ª£c v·ªõi Quantification Type 2\n")
cat("‚Ä¢ Ti√™u ch√≠ ch√≠nh:", VARIABLE_SELECTION_CONFIG$criteria$primary_criterion, "criterion\n")
cat("‚Ä¢ S·ªë th√†nh ph·∫ßn: 10 (c·ªë ƒë·ªãnh)\n")
cat("‚Ä¢ M·ª•c ti√™u ban ƒë·∫ßu: >= 65% ph∆∞∆°ng sai gi·∫£i th√≠ch\n")
cat("‚Ä¢ Ng∆∞·ª°ng d·ª´ng: < 60% ph∆∞∆°ng sai gi·∫£i th√≠ch\n\n")

cat("ƒêI·ªÄU KI·ªÜN D·ª™NG (D·ª∞A NG∆Ø·ª†NG):\n")
cat("‚Ä¢ Ch√≠nh: Ph∆∞∆°ng sai gi·∫£i th√≠ch < 60% (ng∆∞·ª°ng t·ªëi thi·ªÉu)\n")
cat("‚Ä¢ Ph·ª•: 3 v√≤ng l·∫∑p li√™n ti·∫øp kh√¥ng c·∫£i thi·ªán\n") 
cat("‚Ä¢ An to√†n: T·ªëi ƒëa 25 v√≤ng l·∫∑p, t·ªëi thi·ªÉu 5 bi·∫øn\n\n")

cat("K·∫æT QU·∫¢ D·ª∞ KI·∫æN:\n")
cat("‚Ä¢ S·ªë bi·∫øn cu·ªëi c√πng: Ph·ª• thu·ªôc ng∆∞·ª°ng d·ª´ng (kh√¥ng c·ªë ƒë·ªãnh)\n")
cat("‚Ä¢ Ph∆∞∆°ng sai gi·∫£i th√≠ch: >= 60% (ƒë·∫£m b·∫£o t·ªëi thi·ªÉu)\n")
cat("‚Ä¢ ƒê·ªô ph·ª©c t·∫°p m√¥ h√¨nh: T·ªëi ∆∞u theo ng∆∞·ª°ng khoa h·ªçc\n\n")


```

# Section 18: Tri·ªÉn khai ti√™u ch√≠ P (T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch)

```{r}
cat("3.2.1 Tri·ªÉn khai ti√™u ch√≠ P (T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch)\n")
cat("========================================================\n")

# H√†m t√≠nh ti√™u ch√≠ P theo c√¥ng th·ª©c Modified PCA
calculate_P_criterion <- function(subset_eigenvalues, baseline_total_variance, r_components = 10) {
  #  Absolute variance calculation
  if(length(subset_eigenvalues) < r_components) {
    r_components <- length(subset_eigenvalues)
  }
  
  sum_eigenvalues_subset <- sum(subset_eigenvalues[1:r_components])
  P_value_absolute <- sum_eigenvalues_subset / baseline_total_variance
  
  return(list(
    P_value = P_value_absolute,
    sum_eigenvalues = sum_eigenvalues_subset,
    total_variance = baseline_total_variance,
    components_used = r_components,
    variance_explained_pct = P_value_absolute * 100
  ))
}

# H√†m test ti√™u ch√≠ P v·ªõi d·ªØ li·ªáu hi·ªán t·∫°i
test_P_criterion <- function(nlpca_results, r_components = 10) {
  cat("Testing ti√™u ch√≠ P v·ªõi d·ªØ li·ªáu NLPCA hi·ªán t·∫°i:\n")
  
  total_var <- sum(nlpca_results$eigenvalues)
  P_result <- calculate_P_criterion(nlpca_results$eigenvalues, total_var, r_components)
  
  cat(sprintf("‚Ä¢ T·ªïng variance: %.4f\n", P_result$total_variance))
  cat(sprintf("‚Ä¢ Sum eigenvalues (%d components): %.4f\n", 
              P_result$components_used, P_result$sum_eigenvalues))
  cat(sprintf("‚Ä¢ Ti√™u ch√≠ P: %.4f (%.1f%% variance explained)\n", 
              P_result$P_value, P_result$variance_explained_pct))
  
  return(P_result)
}

# Test v·ªõi d·ªØ li·ªáu hi·ªán t·∫°i
if(exists("NLPCA_RESULTS") && NLPCA_RESULTS$convergence_info$converged) {
  P_baseline <- test_P_criterion(NLPCA_RESULTS, 10)
  cat("‚úì ƒê√£ thi·∫øt l·∫≠p baseline cho ti√™u ch√≠ P\n\n")
} else {
  cat("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ NLPCA h·ª£p l·ªá\n\n")
}
```

#Section 19: Tri·ªÉn khai ti√™u ch√≠ RV (H·ªá s·ªë robert-escoufier)

```{r}
cat("3.2.2 Tri·ªÉn khai ti√™u ch√≠ RV \n")
cat("=====================================================\n")

# H√†m t√≠nh h·ªá s·ªë RV gi·ªØa hai ma tr·∫≠n d·ªØ li·ªáu
calculate_RV_coefficient <- function(X, Y) {
  # RV = (Œ£Œª‚±º¬≤)^(1/2) / [tr(X'X)¬≤ √ó tr(Y'Y)¬≤]^(1/2)
  # X: ma tr·∫≠n d·ªØ li·ªáu g·ªëc ho·∫∑c t·∫≠p con
  # Y: ma tr·∫≠n ƒëi·ªÉm th√†nh ph·∫ßn t·ª´ NLPCA
  
  # T√≠nh ma tr·∫≠n t√≠ch v√¥ h∆∞·ªõng
  XtX <- t(X) %*% X
  YtY <- t(Y) %*% Y
  XtY <- t(X) %*% Y
  
  # T√≠nh trace c·ªßa c√°c ma tr·∫≠n b√¨nh ph∆∞∆°ng
  tr_XtX_squared <- sum(diag(XtX %*% XtX))
  tr_YtY_squared <- sum(diag(YtY %*% YtY))
  tr_XtY_squared <- sum(diag(XtY %*% t(XtY)))
  
  # H·ªá s·ªë RV
  numerator <- tr_XtY_squared
  denominator <- sqrt(tr_XtX_squared * tr_YtY_squared)
  
  RV_value <- numerator / denominator
  
  return(list(
    RV_value = RV_value,
    numerator = numerator,
    denominator = denominator,
    tr_XtX_squared = tr_XtX_squared,
    tr_YtY_squared = tr_YtY_squared
  ))
}

# H√†m t√≠nh RV cho t·∫≠p con bi·∫øn t·ª´ NLPCA
calculate_RV_for_subset <- function(original_data, component_scores, variable_subset) {
  # L·∫•y t·∫≠p con d·ªØ li·ªáu theo bi·∫øn ƒë∆∞·ª£c ch·ªçn
  X_subset <- as.matrix(original_data[, variable_subset, drop = FALSE])
  Y_components <- as.matrix(component_scores)
  
  # Chu·∫©n h√≥a d·ªØ li·ªáu (center v√† scale)
  X_subset_scaled <- scale(X_subset, center = TRUE, scale = TRUE)
  Y_components_scaled <- scale(Y_components, center = TRUE, scale = TRUE)
  
  # T√≠nh h·ªá s·ªë RV
  RV_result <- calculate_RV_coefficient(X_subset_scaled, Y_components_scaled)
  
  return(RV_result)
}

# Test v·ªõi d·ªØ li·ªáu hi·ªán t·∫°i
test_RV_criterion <- function(nlpca_results) {
  cat("Testing ti√™u ch√≠ RV v·ªõi d·ªØ li·ªáu NLPCA hi·ªán t·∫°i:\n")
  
  # L·∫•y d·ªØ li·ªáu g·ªëc (ch·ªâ bi·∫øn s·ªë) ƒë·ªÉ test
  numeric_data <- nlpca_results$original_data[, nlpca_results$variable_types$numerical, drop = FALSE]
  
  if(ncol(numeric_data) > 0) {
    RV_result <- calculate_RV_for_subset(
      numeric_data, 
      nlpca_results$object_scores, 
      colnames(numeric_data)
    )
    
    cat(sprintf("‚Ä¢ S·ªë bi·∫øn numeric test: %d\n", ncol(numeric_data)))
    cat(sprintf("‚Ä¢ H·ªá s·ªë RV: %.4f\n", RV_result$RV_value))
    cat(sprintf("‚Ä¢ Numerator: %.2f, Denominator: %.2f\n", 
                RV_result$numerator, RV_result$denominator))
    
    return(RV_result)
  } else {
    cat("Kh√¥ng c√≥ bi·∫øn s·ªë n√†o ƒë·ªÉ ki·ªÉm tra ti√™u ch√≠ RVn")
    return(NULL)
  }
}

if(exists("NLPCA_RESULTS") && NLPCA_RESULTS$convergence_info$converged) {
  RV_baseline <- test_RV_criterion(NLPCA_RESULTS)
  cat("‚úì ƒê√£ thi·∫øt l·∫≠p baseline cho ti√™u ch√≠ RV\n\n")
} else {
  cat("Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ NLPCA h·ª£p l·ªá\n\n")
}
```

#Section 20: Thu·∫≠t to√°n Modified PCA cho d·ªØ li·ªáu h·ªón h·ª£p

```{r}
cat("3.3 Thu·∫≠t to√°n Modified PCA cho d·ªØ li·ªáu h·ªón h·ª£p - Phase A\n")
cat("==================================================================\n")

# H√†m th·ª±c hi·ªán Giai ƒëo·∫°n A: C·ªë ƒë·ªãnh ban ƒë·∫ßu - v·ªõi 65% threshold
phase_A_initialization <- function(nlpca_results, config) {
  cat("3.3.1 GIAI ƒêO·∫†N A: C·ªê ƒê·ªäNH BAN ƒê·∫¶U\n")
  cat("--------------------------------------------------\n")
  
  # A-1: Kh·ªüi t·∫°o v·ªõi to√†n b·ªô bi·∫øn
  all_variables <- colnames(nlpca_results$original_data)
  Y1_initial <- all_variables
  
  cat(sprintf("A-1: Kh·ªüi t·∫°o v·ªõi %d bi·∫øn\n", length(Y1_initial)))
  
  # A-2: S·ª≠ d·ª•ng eigenvalues t·ª´ NLPCA ƒë√£ c√≥
  eigenvalues <- nlpca_results$eigenvalues
  cat(sprintf("A-2: S·ª≠ d·ª•ng %d eigenvalues t·ª´ NLPCA\n", length(eigenvalues)))
  
  # A-3: X√°c ƒë·ªãnh s·ªë th√†nh ph·∫ßn ch√≠nh r - v·ªõi 65% threshold
  total_variance <- sum(eigenvalues)
  cumsum_variance <- cumsum(eigenvalues) / total_variance
  
  #  FIXED: Ch·ªçn r sao cho gi·∫£i th√≠ch √≠t nh·∫•t 65% variance
  r_components <- which(cumsum_variance >= config$stopping_criteria$initial_variance_target)[1]
  if(is.na(r_components)) {
    r_components <- min(length(eigenvalues), config$nlpca_settings$ndim)  # Fallback to 10 components
    warning("Kh√¥ng ƒë·∫°t 65% variance, s·ª≠ d·ª•ng fallback")
  }
  
  cat(sprintf("A-3: Ch·ªçn r = %d th√†nh ph·∫ßn (%.1f%% variance) - Target ‚â•65%%\n", 
              r_components, cumsum_variance[r_components] * 100))
  
  # A-4: Bi·∫øn quan tr·ªçng (n·∫øu c√≥)
  core_vars <- config$protected_variables$core_vars
  if(length(core_vars) > 0) {
    cat(sprintf("A-4: B·∫£o v·ªá %d bi·∫øn quan tr·ªçng\n", length(core_vars)))
  } else {
    cat("A-4: Kh√¥ng c√≥ bi·∫øn quan tr·ªçng ƒë∆∞·ª£c b·∫£o v·ªá\n")
  }
  
  # A-5: Baseline evaluation v·ªõi r components ƒë√£ ch·ªçn
  baseline_P <- calculate_P_criterion(eigenvalues, total_variance, r_components)
  cat(sprintf("A-5: Baseline P-criterion = %.4f (%.1f%% variance)\n", 
              baseline_P$P_value, baseline_P$variance_explained_pct))
  
  return(list(
    Y1_initial = Y1_initial,
    eigenvalues = eigenvalues,
    total_variance = total_variance,
    r_components = r_components,           #  S·ª≠ d·ª•ng r t√≠nh t·ª´ 65% threshold
    core_variables = core_vars,
    cumulative_variance = cumsum_variance,
    baseline_P_criterion = baseline_P
  ))
}

# Th·ª±c hi·ªán Phase A v·ªõi c·∫•u h√¨nh fixed
if(exists("NLPCA_RESULTS") && exists("VARIABLE_SELECTION_CONFIG")) {
  phase_A_results <- phase_A_initialization(NLPCA_RESULTS, VARIABLE_SELECTION_CONFIG)
  cat("‚úì Ho√†n th√†nh Giai ƒëo·∫°n A \n\n")
} else {
  cat("Thi·∫øu d·ªØ li·ªáu ƒë·∫ßu v√†o cho Phase A\n\n")
}
```

# Section 21: Data preparation functions
```{r}
cat("3.4 Data preparation functions\n")
cat("==============================================================\n")

# Function ƒë·ªÉ clean v√† prepare data cho Gifi - UPDATED VERSION
prepare_data_for_gifi_standardized <- function(data, measurement_levels, variable_subset, verbose = FALSE) {
  
  if(verbose) cat(" Chu·∫©n b·ªã d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a cho thu·∫≠t to√°n Gifi:\n")
  
  # Step 1: Extract subset
  clean_data <- data[, variable_subset, drop = FALSE]
  clean_levels <- measurement_levels[variable_subset]
  
  if(verbose) cat(sprintf("‚Ä¢ Original subset: %d √ó %d\n", nrow(clean_data), ncol(clean_data)))
  
  # Step 2: Handle each variable based on measurement level
  for(var in variable_subset) {
    original_class <- class(clean_data[[var]])[1]
    measurement_level <- clean_levels[var]
    
    if(verbose) cat(sprintf("‚Ä¢ Processing %s (%s ‚Üí %s)\n", var, original_class, measurement_level))
    
    if(measurement_level == "metric") {
      # Data ƒë√£ ƒë∆∞·ª£c standardized, ch·ªâ c·∫ßn ƒë·∫£m b·∫£o l√† numeric
      if(!is.numeric(clean_data[[var]])) {
        if(verbose) cat(sprintf("  ‚Üí Converting %s to numeric (already standardized)\n", var))
        clean_data[[var]] <- as.numeric(as.character(clean_data[[var]]))
      } else {
        if(verbose) cat(sprintf("  ‚Üí %s already numeric and standardized\n", var))
      }
      
      # Ki·ªÉm tra standardization quality
      var_mean <- mean(clean_data[[var]], na.rm = TRUE)
      var_sd <- sd(clean_data[[var]], na.rm = TRUE)
      if(verbose && abs(var_mean) > 0.1) {
        cat(sprintf("  ‚ö† Warning: %s may not be properly standardized (mean=%.3f)\n", var, var_mean))
      }
      
    } else if(measurement_level %in% c("nominal", "ordinal")) {
      # Ensure factor for categorical variables (unchanged logic)
      if(!is.factor(clean_data[[var]])) {
        if(verbose) cat(sprintf("  ‚Üí Converting %s to factor\n", var))
        clean_data[[var]] <- as.factor(as.character(clean_data[[var]]))
      }
      
      # Drop unused factor levels
      if(is.factor(clean_data[[var]])) {
        before_levels <- nlevels(clean_data[[var]])
        clean_data[[var]] <- droplevels(clean_data[[var]])
        after_levels <- nlevels(clean_data[[var]])
        
        if(before_levels != after_levels && verbose) {
          cat(sprintf("  ‚Üí Dropped %d unused factor levels\n", before_levels - after_levels))
        }
      }
      
      # Handle ordinal specifically (unchanged logic)
      if(measurement_level == "ordinal") {
        if(!is.ordered(clean_data[[var]])) {
          if(verbose) cat(sprintf("  ‚Üí Making %s ordered factor\n", var))
          
          if(var == "Education") {
            education_order <- c("Basic", "2n Cycle", "Graduation", "Master", "PhD")
            available_levels <- intersect(education_order, levels(clean_data[[var]]))
            clean_data[[var]] <- factor(clean_data[[var]], levels = available_levels, ordered = TRUE)
          } else {
            clean_data[[var]] <- factor(clean_data[[var]], ordered = TRUE)
          }
        }
      }
    }
  }
  
  # Step 3: Remove rows with too many NAs (unchanged logic)
  na_counts <- rowSums(is.na(clean_data))
  max_na_allowed <- floor(ncol(clean_data) * 0.5)
  valid_rows <- na_counts <= max_na_allowed
  
  if(sum(!valid_rows) > 0) {
    if(verbose) cat(sprintf("‚Ä¢ Removing %d rows with >50%% missing data\n", sum(!valid_rows)))
    clean_data <- clean_data[valid_rows, , drop = FALSE]
  }
  
  # Step 4: Final validation
  final_na_pct <- (sum(is.na(clean_data)) / (nrow(clean_data) * ncol(clean_data))) * 100
  
  # Additional check for standardized numeric variables
  numeric_vars <- names(clean_levels)[clean_levels == "metric"]
  numeric_vars <- intersect(numeric_vars, names(clean_data))
  
  standardization_quality <- TRUE
  if(length(numeric_vars) > 0) {
    for(var in numeric_vars) {
      var_mean <- mean(clean_data[[var]], na.rm = TRUE)
      var_sd <- sd(clean_data[[var]], na.rm = TRUE)
      if(abs(var_mean) > 0.2 || abs(var_sd - 1) > 0.2) {
        standardization_quality <- FALSE
        if(verbose) {
          cat(sprintf("  ‚ö† Standardization concern for %s: mean=%.3f, sd=%.3f\n", 
                      var, var_mean, var_sd))
        }
      }
    }
  }
  
  if(verbose) {
    cat(sprintf(" Cleaned data: %d √ó %d\n", nrow(clean_data), ncol(clean_data)))
    cat(sprintf(" Overall NA percentage: %.1f%%\n", final_na_pct))
    cat(sprintf(" Standardization quality: %s\n", ifelse(standardization_quality, "Good", "Check needed")))
  }
  
  return(list(
    data = clean_data,
    levels = clean_levels,
    success = TRUE,
    na_percentage = final_na_pct,
    standardization_quality = standardization_quality,
    note = "Data preprocessing completed for standardized mixed data"
  ))
}

cat(" Chu·∫©n b·ªã d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a ƒë·ªÉ th·ª±c hi·ªán ph∆∞∆°ng ph√°p Gifi th√†nh c√¥ng\n\n")
```

# Section 22: H√†m ƒë√°nh gi√° c·ªë ƒë·ªãnh
```{r}
cat("3.5 H√†m ƒë√°nh gi√° c·ªë ƒë·ªãnh\n")
cat("==========================================================\n")

# Phi√™n b·∫£n c·∫≠p nh·∫≠t c·ªßa h√†m evaluate_variable_subset_option2_fixed
evaluate_variable_subset_option2_standardized <- function(variable_subset, original_standardized_data, measurement_levels, config, baseline_total_variance = NULL, verbose = FALSE) {
  
  if(verbose) {
    cat(sprintf(" ƒêang ƒë√°nh gi√° t·∫≠p con v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a: %d bi·∫øn (%s)\n", 
                length(variable_subset), paste(variable_subset[1:min(3, length(variable_subset))], collapse = ", ")))
  }
  
  # Ki·ªÉm tra s·ªë l∆∞·ª£ng bi·∫øn t·ªëi thi·ªÉu
  if(length(variable_subset) < 2) {
    return(list(
      success = FALSE,
      error = "T·∫≠p con ph·∫£i c√≥ √≠t nh·∫•t 2 bi·∫øn",
      variable_subset = variable_subset,
      n_variables = length(variable_subset)
    ))
  }
  
  # Ki·ªÉm tra bi·∫øn c√≥ t·ªìn t·∫°i trong d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a kh√¥ng
  missing_vars <- setdiff(variable_subset, names(original_standardized_data))
  if(length(missing_vars) > 0) {
    return(list(
      success = FALSE,
      error = paste("C√°c bi·∫øn kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu chu·∫©n h√≥a:", paste(missing_vars, collapse = ", ")),
      variable_subset = variable_subset,
      missing_variables = missing_vars
    ))
  }
  
  # B∆∞·ªõc 1: L√†m s·∫°ch d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a b·∫±ng h√†m updated
  if(verbose) cat("  ‚Üí ƒêang l√†m s·∫°ch d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a...\n")
  
  clean_result <- prepare_data_for_gifi_standardized(
    original_standardized_data, 
    measurement_levels, 
    variable_subset, 
    verbose = FALSE
  )
  
  if(!clean_result$success) {
    return(list(
      success = FALSE,
      error = "Qu√° tr√¨nh l√†m s·∫°ch d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a th·∫•t b·∫°i",
      variable_subset = variable_subset,
      cleaning_error = clean_result$error
    ))
  }
  
  clean_data <- clean_result$data
  clean_levels <- clean_result$levels
  
  # Ki·ªÉm tra ch·∫•t l∆∞·ª£ng chu·∫©n h√≥a
  if(!clean_result$standardization_quality && verbose) {
    cat("  ‚ö† C·∫£nh b√°o: Ch·∫•t l∆∞·ª£ng chu·∫©n h√≥a c√≥ th·ªÉ c√≥ v·∫•n ƒë·ªÅ\n")
  }
  
  # Ki·ªÉm tra ƒë·ªß d·ªØ li·ªáu sau khi l√†m s·∫°ch
  if(nrow(clean_data) < 10) {
    return(list(
      success = FALSE,
      error = paste("Kh√¥ng ƒë·ªß d·ªØ li·ªáu sau khi l√†m s·∫°ch:", nrow(clean_data), "d√≤ng"),
      variable_subset = variable_subset
    ))
  }
  
  if(verbose) cat(sprintf("  ‚Üí D·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a sau khi l√†m s·∫°ch: %d √ó %d\n", nrow(clean_data), ncol(clean_data)))
  
  # B∆∞·ªõc 2: Th·ª≠ th·ª±c hi·ªán NLPCA v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
  nlpca_configs <- list(
    list(ndim = config$nlpca_settings$ndim, itmax = config$nlpca_settings$max_iterations, eps = config$nlpca_settings$tolerance),
    list(ndim = 5, itmax = 50, eps = 1e-4),
    list(ndim = 8, itmax = 30, eps = 1e-3)
  )
  
  subset_nlpca <- NULL
  config_used <- NULL
  
  for(i in 1:length(nlpca_configs)) {
    nlpca_config <- nlpca_configs[[i]]
    
    if(verbose) cat(sprintf("  ‚Üí Th·ª±c hi·ªán NLPCA l·∫ßn %d v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a: ndim=%d\n", i, nlpca_config$ndim))
    
    tryCatch({
      set.seed(config$nlpca_settings$seed)
      
      subset_nlpca <- Gifi::princals(
        data = clean_data,  # D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a
        ndim = nlpca_config$ndim,
        levels = clean_levels,
        verbose = FALSE,
        itmax = nlpca_config$itmax,
        eps = nlpca_config$eps
      )
      
      config_used <- nlpca_config
      break  # Th√†nh c√¥ng!
      
    }, error = function(e) {
      if(verbose) cat(sprintf("    Kh√¥ng th√†nh c√¥ng: %s\n", e$message))
      return(NULL)
    })
  }
  
  # Ki·ªÉm tra k·∫øt qu·∫£ NLPCA
  if(is.null(subset_nlpca)) {
    return(list(
      success = FALSE,
      error = "Kh√¥ng c√≥ l·∫ßn th·ª±c hi·ªán NLPCA n√†o th√†nh c√¥ng v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a",
      variable_subset = variable_subset,
      n_variables = length(variable_subset),
      data_rows_after_cleaning = nrow(clean_data)
    ))
  }
  
  if(verbose) {
    cat(sprintf("   NLPCA th√†nh c√¥ng v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a: %d v√≤ng l·∫∑p, loss=%.6f, ndim=%d\n", 
                subset_nlpca$ntel, subset_nlpca$f, config_used$ndim))
  }
  
  # B∆∞·ªõc 3: T√≠nh c√°c ti√™u ch√≠ t·ª´ k·∫øt qu·∫£ NLPCA
  true_eigenvalues <- subset_nlpca$evals
  total_variance_subset <- sum(true_eigenvalues)
  
  evaluation_result <- list(
    success = TRUE,
    variable_subset = variable_subset,
    n_variables = length(variable_subset),
    data_rows_used = nrow(clean_data),
    ndim_used = config_used$ndim,
    standardized_data_used = TRUE,  # FLAG m·ªõi
    convergence_info = list(
      iterations = subset_nlpca$ntel,
      loss = subset_nlpca$f,
      converged = TRUE,
      config_used = config_used
    )
  )
  
  # T√≠nh ti√™u ch√≠ P t·ª´ eigenvalues (logic kh√¥ng ƒë·ªïi)
  if(config$criteria$use_P_criterion) {
    actual_baseline <- if(!is.null(baseline_total_variance)) {
      baseline_total_variance
    } else {
      sum(true_eigenvalues)
    }
    
    P_result <- calculate_P_criterion(
      true_eigenvalues,
      actual_baseline,
      config_used$ndim
    )
    evaluation_result$P_criterion <- P_result
    
    if(verbose) {
      cat(sprintf("  ‚Üí Ti√™u ch√≠ P (v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a): %.4f (%.1f%%)\n", 
                  P_result$P_value, P_result$variance_explained_pct))
    }
  }
  
  # T√≠nh ti√™u ch√≠ RV t·ª´ ƒëi·ªÉm th√†nh ph·∫ßn NLPCA (c·∫≠p nh·∫≠t)
  if(config$criteria$use_RV_criterion) {
    numeric_vars_subset <- intersect(variable_subset, names(original_standardized_data)[sapply(original_standardized_data, is.numeric)])
    
    if(length(numeric_vars_subset) > 0) {
      # S·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a cho RV calculation
      RV_result <- calculate_RV_for_subset(
        original_standardized_data[, numeric_vars_subset, drop = FALSE],
        subset_nlpca$objectscores,
        numeric_vars_subset
      )
      evaluation_result$RV_criterion <- RV_result
      
      if(verbose) {
        cat(sprintf("  ‚Üí Ti√™u ch√≠ RV (v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a): %.4f\n", RV_result$RV_value))
      }
    } else {
      evaluation_result$RV_criterion <- list(RV_value = 0)
    }
  }
  
  # Ch·ªçn ƒëi·ªÉm ch√≠nh ƒë·ªÉ so s√°nh (logic kh√¥ng ƒë·ªïi)
  if(config$criteria$primary_criterion == "P") {
    evaluation_result$primary_score <- evaluation_result$P_criterion$P_value
  } else {
    evaluation_result$primary_score <- evaluation_result$RV_criterion$RV_value
  }
  
  # L∆∞u k·∫øt qu·∫£ NLPCA ƒë·ªÉ ƒë·ªëi chi·∫øu
  evaluation_result$subset_nlpca_results <- list(
    eigenvalues = true_eigenvalues,
    object_scores = subset_nlpca$objectscores,
    loadings = subset_nlpca$loadings,
    quantifications = subset_nlpca$quantifications
  )
  
  return(evaluation_result)
}

cat("H√†m ƒë√°nh gi√° ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t cho d·ªØ li·ªáu chu·∫©n h√≥a.\n\n")
```

#Section 23: Thu·∫≠t to√°n lo·∫°i tr·ª´ bi·∫øn l√πi

```{r}
# Section 24: Thu·∫≠t to√°n lo·∫°i tr·ª´ bi·∫øn l√πi
cat("3.6 THU·∫¨T TO√ÅN LO·∫†I BI·∫æN NG∆Ø·ª¢C - PH∆Ø∆†NG SAI TUY·ªÜT ƒê·ªêI\n")
cat("=================================================================\n")

# Thu·∫≠t to√°n lo·∫°i bi·∫øn ng∆∞·ª£c v·ªõi ph∆∞∆°ng sai tuy·ªát ƒë·ªëi - s·ª≠ d·ª•ng d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
backward_elimination_threshold_based_standardized <- function(nlpca_results, phase_A_results, config) {
  
  cat("B·∫Øt ƒë·∫ßu th·ª±c thi thu·∫≠t to√°n lo·∫°i bi·∫øn ng∆∞·ª£c v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a\n")
  cat("=====================================================================\n")
  cat("‚Ä¢ Ph∆∞∆°ng ph√°p: T√≠nh l·∫°i NLPCA t·ª´ng l·∫ßn v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a Z-score\n")
  cat("‚Ä¢ So s√°nh v·ªõi: Gi√° tr·ªã baseline ph∆∞∆°ng sai t·ª´ t·∫≠p bi·∫øn g·ªëc (ƒë√£ chu·∫©n h√≥a)\n")
  cat("‚Ä¢ ƒêi·ªÅu ki·ªán d·ª´ng: Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi < 60% baseline\n")
  cat("‚Ä¢ S·ªë th√†nh ph·∫ßn gi·ªØ c·ªë ƒë·ªãnh: 10\n")
  cat("‚Ä¢ D·ªØ li·ªáu: Bi·∫øn ƒë·ªãnh l∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a Z-score\n\n")
  
  # Kh·ªüi t·∫°o bi·∫øn
  current_variables <- phase_A_results$Y1_initial
  core_vars <- phase_A_results$core_variables
  
  # L·∫•y baseline t·ªïng ph∆∞∆°ng sai t·ª´ t·∫≠p bi·∫øn g·ªëc (ƒë√£ chu·∫©n h√≥a)
  baseline_total_variance <- phase_A_results$baseline_P_criterion$total_variance
  
  cat(sprintf("T·ªïng ph∆∞∆°ng sai baseline (t·ª´ d·ªØ li·ªáu chu·∫©n h√≥a): %.4f (t·ª´ %d bi·∫øn ban ƒë·∫ßu)\n", 
              baseline_total_variance, length(current_variables)))
  
  history <- list()
  iteration <- 0
  failed_evaluations <- 0
  consecutive_no_improvement <- 0
  
  # ƒê√°nh gi√° baseline v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
  cat("\nGiai ƒëo·∫°n A: ƒê√°nh gi√° baseline (d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a)\n")
  
  baseline_eval <- evaluate_variable_subset_option2_standardized(
    current_variables, 
    nlpca_results$original_data,  # ƒê√£ l√† d·ªØ li·ªáu chu·∫©n h√≥a
    nlpca_results$measurement_levels, 
    config,
    baseline_total_variance,
    verbose = TRUE
  )
  
  if(!baseline_eval$success) {
    cat("Kh√¥ng th·ªÉ ƒë√°nh gi√° baseline v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a: ", baseline_eval$error, "\n")
    return(list(
      success = FALSE,
      error = "Kh√¥ng th·ªÉ th·ª±c hi·ªán ƒë√°nh gi√° baseline v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a",
      final_variables = current_variables,
      history = list(),
      iterations = 0
    ))
  }
  
  # L∆∞u baseline v√†o l·ªãch s·ª≠
  history[[1]] <- list(
    iteration = 0,
    variables = current_variables,
    n_variables = length(current_variables),
    evaluation = baseline_eval,
    action = "baseline_A_standardized"
  )
  
  # Kh·ªüi t·∫°o ƒëi·ªÉm s·ªë an to√†n
  current_score <- if(!is.null(baseline_eval$primary_score)) {
    baseline_eval$primary_score
  } else {
    0
  }
  
  current_variance_absolute_pct <- if(!is.null(baseline_eval$P_criterion)) {
    baseline_eval$P_criterion$variance_explained_pct
  } else { 
    100 
  }
  
  # Ki·ªÉm tra ƒëi·ªÉm s·ªë hi·ªán t·∫°i
  if(is.null(current_score) || length(current_score) == 0 || is.na(current_score)) {
    cat("C·∫£nh b√°o: ƒêi·ªÉm baseline kh√¥ng h·ª£p l·ªá, ƒë·∫∑t v·ªÅ 0\n")
    current_score <- 0
  }
  
  cat(sprintf("Baseline (d·ªØ li·ªáu chu·∫©n h√≥a): %d bi·∫øn\n", length(current_variables)))
  cat(sprintf("   ƒêi·ªÉm s·ªë: %.4f\n", current_score))
  cat(sprintf("   Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi: %.1f%% (so v·ªõi baseline chu·∫©n h√≥a)\n", current_variance_absolute_pct))
  cat(sprintf("   Standardized data used: %s\n", baseline_eval$standardized_data_used))
  
  cat("\nGiai ƒëo·∫°n B: Lo·∫°i bi·∫øn ng∆∞·ª£c theo ph∆∞∆°ng sai tuy·ªát ƒë·ªëi (d·ªØ li·ªáu chu·∫©n h√≥a)\n")
  cat(paste(rep("-", 60), collapse = ""), "\n")
  
  # V√≤ng l·∫∑p ch√≠nh lo·∫°i bi·∫øn (logic kh√¥ng ƒë·ªïi, ch·ªâ s·ª≠ d·ª•ng h√†m m·ªõi)
  while(iteration < config$stopping_criteria$max_iterations && 
        length(current_variables) > config$strategy$min_variables &&
        consecutive_no_improvement < config$stopping_criteria$consecutive_no_improvement) {
    
    iteration <- iteration + 1
    cat(sprintf("\nL·∫ßn l·∫∑p %d (d·ªØ li·ªáu chu·∫©n h√≥a): %d bi·∫øn, Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi: %.1f%%\n", 
                iteration, length(current_variables), current_variance_absolute_pct))
    
    # X√°c ƒë·ªãnh c√°c bi·∫øn c√≥ th·ªÉ lo·∫°i b·ªè
    removable_vars <- setdiff(current_variables, core_vars)
    
    if(length(removable_vars) == 0) {
      cat("Kh√¥ng th·ªÉ lo·∫°i b·ªè th√™m bi·∫øn (t·∫•t c·∫£ ƒë·ªÅu l√† bi·∫øn quan tr·ªçng)\n")
      break
    }
    
    cat(sprintf("ƒêang ƒë√°nh gi√° %d bi·∫øn c√≥ th·ªÉ lo·∫°i b·ªè (d·ªØ li·ªáu chu·∫©n h√≥a)...\n", length(removable_vars)))
    
    # Kh·ªüi t·∫°o bi·∫øn cho l·∫ßn l·∫∑p n√†y
    best_score <- -Inf
    best_subset <- NULL
    best_removed_var <- NULL
    best_evaluation <- NULL
    best_variance_absolute_pct <- 0
    valid_subsets_found <- FALSE
    
    # Ki·ªÉm tra ƒëi·ªÉm s·ªë tr∆∞·ªõc khi l·∫∑p
    if(is.null(current_score) || length(current_score) == 0 || is.na(current_score)) {
      cat("C·∫£nh b√°o: ƒêi·ªÉm hi·ªán t·∫°i kh√¥ng h·ª£p l·ªá, b·ªè qua l·∫ßn l·∫∑p n√†y\n")
      break
    }
    
    # ƒê√°nh gi√° t·ª´ng subset khi lo·∫°i b·ªè m·ªôt bi·∫øn
    for(i in 1:length(removable_vars)) {
      var_to_remove <- removable_vars[i]
      temp_subset <- setdiff(current_variables, var_to_remove)
      
      cat(sprintf("  %d/%d: Lo·∫°i '%s' (%d bi·∫øn c√≤n l·∫°i)...", 
                  i, length(removable_vars), var_to_remove, length(temp_subset)))
      
      temp_eval <- tryCatch({
        evaluate_variable_subset_option2_standardized(  # S·ª¨ D·ª§NG H√ÄM M·ªöI
          temp_subset, 
          nlpca_results$original_data,  # D·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
          nlpca_results$measurement_levels, 
          config,
          baseline_total_variance,
          verbose = FALSE
        )
      }, error = function(e) {
        list(success = FALSE, error = e$message)
      })
      
      if(temp_eval$success) {
        temp_absolute_pct <- if(!is.null(temp_eval$P_criterion)) {
          temp_eval$P_criterion$variance_explained_pct
        } else { 
          0 
        }
        
        cat(sprintf(" Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi: %.1f%%", temp_absolute_pct))
        
        # Ki·ªÉm tra ng∆∞·ª°ng ph∆∞∆°ng sai tuy·ªát ƒë·ªëi
        if(temp_absolute_pct >= config$stopping_criteria$min_variance_threshold * 100) {
          cat(" (ƒê·∫°t ‚â• 60%)")
          valid_subsets_found <- TRUE
          
          # Ch·ªçn subset t·ªët nh·∫•t ƒë·∫°t ng∆∞·ª°ng
          if(temp_eval$primary_score > best_score) {
            best_score <- temp_eval$primary_score
            best_subset <- temp_subset
            best_removed_var <- var_to_remove
            best_evaluation <- temp_eval
            best_variance_absolute_pct <- temp_absolute_pct
          }
        } else {
          cat(" (Kh√¥ng ƒë·∫°t ng∆∞·ª°ng 60%)")
        }
        cat("\n")
        
      } else {
        cat(sprintf(" Kh√¥ng ƒë√°nh gi√° ƒë∆∞·ª£c: %s\n", temp_eval$error))
        failed_evaluations <- failed_evaluations + 1
        
        # D·ª´ng khi g·∫∑p qu√° nhi·ªÅu l·ªói
        if(failed_evaluations > length(removable_vars) * 0.5) {
          cat("C√≥ qu√° nhi·ªÅu l·ªói NLPCA v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a - d·ª´ng ƒë·ªÉ tr√°nh b·∫•t ·ªïn\n")
          break
        }
      }
    }
    
    # Quy·∫øt ƒë·ªãnh lo·∫°i bi·∫øn d·ª±a tr√™n k·∫øt qu·∫£ ƒë√°nh gi√° (logic kh√¥ng ƒë·ªïi)
    if(!valid_subsets_found || is.null(best_subset)) {
      cat("D·ª™NG: Kh√¥ng c√≥ subset n√†o ƒë·∫°t ng∆∞·ª°ng 60% ph∆∞∆°ng sai tuy·ªát ƒë·ªëi (d·ªØ li·ªáu chu·∫©n h√≥a)\n")
      cat("ƒêi·ªÉm d·ª´ng t·ªëi ∆∞u theo ti√™u ch√≠ khoa h·ªçc\n")
      break
    }
    
    if(is.null(best_score) || length(best_score) == 0 || is.na(best_score) || best_score == -Inf) {
      cat("D·ª™NG: Kh√¥ng t√¨m ƒë∆∞·ª£c ƒëi·ªÉm s·ªë h·ª£p l·ªá cho b·∫•t k·ª≥ subset n√†o\n")
      break
    }
    
    # Ki·ªÉm tra m·ª©c c·∫£i thi·ªán (logic kh√¥ng ƒë·ªïi)
    improvement <- best_score - current_score
    if(is.null(improvement) || length(improvement) == 0 || is.na(improvement)) {
      improvement <- 0
      cat("C·∫£nh b√°o: Gi√° tr·ªã c·∫£i thi·ªán kh√¥ng h·ª£p l·ªá, ƒë·∫∑t v·ªÅ 0\n")
    }
    
    min_improvement_threshold <- config$stopping_criteria$min_improvement_threshold
    if(is.null(min_improvement_threshold) || is.na(min_improvement_threshold)) {
      min_improvement_threshold <- -0.02
      cat("C·∫£nh b√°o: min_improvement_threshold kh√¥ng h·ª£p l·ªá, d√πng m·∫∑c ƒë·ªãnh -0.02\n")
    }
    
    if(improvement < min_improvement_threshold) {
      consecutive_no_improvement <- consecutive_no_improvement + 1
      cat(sprintf("C·∫£i thi·ªán th·∫•p: %+.4f (l·∫ßn %d)\n", improvement, consecutive_no_improvement))
    } else {
      consecutive_no_improvement <- 0
    }
    
    # √Åp d·ª•ng thay ƒë·ªïi t·ªët nh·∫•t
    current_variables <- best_subset
    current_score <- best_score
    current_variance_absolute_pct <- best_variance_absolute_pct
    baseline_eval <- best_evaluation
    
    if(is.null(current_score) || length(current_score) == 0 || is.na(current_score)) {
      cat("C·∫£nh b√°o: ƒêi·ªÉm s·ªë hi·ªán t·∫°i kh√¥ng h·ª£p l·ªá sau khi c·∫≠p nh·∫≠t\n")
      current_score <- 0
    }
    
    # L∆∞u l·∫°i l·ªãch s·ª≠
    history[[iteration + 1]] <- list(
      iteration = iteration,
      variables = current_variables,
      n_variables = length(current_variables),
      removed_variable = best_removed_var,
      evaluation = best_evaluation,
      improvement = improvement,
      absolute_variance_pct = current_variance_absolute_pct,
      action = "remove_variable_standardized_data"
    )
    
    cat(sprintf("ƒê√£ lo·∫°i b·ªè bi·∫øn '%s': c√≤n l·∫°i %d bi·∫øn\n", best_removed_var, length(current_variables)))
    cat(sprintf("   ƒêi·ªÉm s·ªë: %.4f ‚Üí %.4f (%+.4f)\n", 
                current_score - improvement, current_score, improvement))
    cat(sprintf("   Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi: %.1f%% (‚â• %.0f%% ng∆∞·ª°ng)\n", 
                current_variance_absolute_pct, config$stopping_criteria$min_variance_threshold * 100))
  }
  
  # T√≥m t·∫Øt k·∫øt qu·∫£
  final_score <- if(!is.null(current_score) && length(current_score) > 0 && !is.na(current_score)) {
    current_score
  } else {
    0
  }
  
  final_variance <- if(!is.null(current_variance_absolute_pct) && length(current_variance_absolute_pct) > 0 && !is.na(current_variance_absolute_pct)) {
    current_variance_absolute_pct
  } else {
    0
  }
  
  cat("\n", paste(rep("=", 70), collapse = ""), "\n")
  cat("ƒê√£ ho√†n th√†nh thu·∫≠t to√°n lo·∫°i bi·∫øn ng∆∞·ª£c v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a.\n")
  cat(sprintf("‚Ä¢ Bi·∫øn ban ƒë·∫ßu: %d ‚Üí Bi·∫øn cu·ªëi: %d\n", 
              length(phase_A_results$Y1_initial), length(current_variables)))
  cat(sprintf("‚Ä¢ S·ªë l·∫ßn l·∫∑p: %d\n", iteration))
  cat(sprintf("‚Ä¢ S·ªë l·∫ßn ƒë√°nh gi√° th·∫•t b·∫°i: %d\n", failed_evaluations))
  cat(sprintf("‚Ä¢ Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi cu·ªëi c√πng: %.1f%% (so v·ªõi baseline chu·∫©n h√≥a)\n", final_variance))
  cat(sprintf("‚Ä¢ ƒêi·ªÉm s·ªë cu·ªëi c√πng: %.4f\n", final_score))
  cat("‚Ä¢ Ti√™u ch√≠ so s√°nh: Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a Z-score\n")
  cat("‚Ä¢ D·ªØ li·ªáu ƒë·∫ßu v√†o: Bi·∫øn ƒë·ªãnh l∆∞·ª£ng ƒë√£ chu·∫©n h√≥a Z-score, bi·∫øn ƒë·ªãnh t√≠nh kh√¥ng ƒë·ªïi\n")
  cat(paste(rep("=", 70), collapse = ""), "\n\n")
  
  return(list(
    success = TRUE,
    method = "absolute_variance_backward_elimination_standardized",
    final_variables = current_variables,
    history = history,
    iterations = iteration,
    final_evaluation = baseline_eval,
    final_absolute_variance_pct = final_variance,
    baseline_total_variance = baseline_total_variance,
    removed_variables = setdiff(phase_A_results$Y1_initial, current_variables),
    failed_evaluations = failed_evaluations,
    stopping_reason = "absolute_variance_threshold_based_standardized",
    config_used = config,
    standardized_data_used = TRUE  # FLAG m·ªõi
  ))
}

cat("Thu·∫≠t to√°n lo·∫°i bi·∫øn ng∆∞·ª£c d·ª±a tr√™n d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a ƒë√£ ƒë∆∞·ª£c n·∫°p th√†nh c√¥ng.\n")
```

#Section 24: Th·ª±c thi thu·∫≠t to√°n

```{r}
# Section 25: Th·ª±c thi thu·∫≠t to√°n
cat("==========================================================\n")

# H√†m bao ƒë·ªÉ th·ª±c thi lo·∫°i bi·∫øn ng∆∞·ª£c v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
execute_standardized_backward_elimination <- function(nlpca_results) {
  
  cat("Th·ª±c thi quy tr√¨nh lo·∫°i bi·∫øn ng∆∞·ª£c v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a Z-score\n")
  cat("====================================================================\n")
  cat("‚Ä¢ D·ªØ li·ªáu ƒë·∫ßu v√†o: Bi·∫øn ƒë·ªãnh l∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a Z-score (mean‚âà0, sd‚âà1)\n")
  cat("‚Ä¢ Bi·∫øn ƒë·ªãnh t√≠nh: Gi·ªØ nguy√™n c·∫•u tr√∫c factor/ordered factor\n")
  cat("‚Ä¢ L·ª£i √≠ch: Lo·∫°i b·ªè ·∫£nh h∆∞·ªüng c·ªßa ƒë∆°n v·ªã ƒëo l∆∞·ªùng, tƒÉng t√≠nh c√¥ng b·∫±ng gi·ªØa c√°c bi·∫øn\n\n")
  
  # Ki·ªÉm tra c·∫•u h√¨nh ƒë·∫ßu v√†o
  if(!exists("VARIABLE_SELECTION_CONFIG")) {
    cat("C·∫•u h√¨nh VARIABLE_SELECTION_CONFIG kh√¥ng t·ªìn t·∫°i.\n")
    return(list(success = FALSE, error = "Thi·∫øu c·∫•u h√¨nh"))
  }
  
  if(is.null(nlpca_results) || !nlpca_results$convergence_info$converged) {
    cat("ƒê·∫ßu v√†o NLPCA_RESULTS kh√¥ng h·ª£p l·ªá ho·∫∑c ch∆∞a h·ªôi t·ª•.\n")
    return(list(success = FALSE, error = "NLPCA_RESULTS kh√¥ng h·ª£p l·ªá"))
  }
  
  # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a ch∆∞a
  cat("Ki·ªÉm tra t√¨nh tr·∫°ng chu·∫©n h√≥a d·ªØ li·ªáu:\n")
  numeric_vars <- names(nlpca_results$measurement_levels)[nlpca_results$measurement_levels == "metric"]
  numeric_vars <- intersect(numeric_vars, names(nlpca_results$original_data))
  
  standardization_check <- TRUE
  for(var in numeric_vars) {
    if(var %in% names(nlpca_results$original_data)) {
      var_mean <- mean(nlpca_results$original_data[[var]], na.rm = TRUE)
      var_sd <- sd(nlpca_results$original_data[[var]], na.rm = TRUE)
      cat(sprintf("‚Ä¢ %s: mean=%.3f, sd=%.3f", var, var_mean, var_sd))
      
      if(abs(var_mean) > 0.1 || abs(var_sd - 1) > 0.1) {
        cat(" ‚ö† Ch∆∞a chu·∫©n h√≥a\n")
        standardization_check <- FALSE
      } else {
        cat(" ‚úì ƒê√£ chu·∫©n h√≥a\n")
      }
    }
  }
  
  if(!standardization_check) {
    cat("\n C·∫¢NH B√ÅO: D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c chu·∫©n h√≥a ƒë√∫ng c√°ch!\n")
    cat("Vui l√≤ng ch·∫°y Section 8.5 ƒë·ªÉ chu·∫©n h√≥a d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øp t·ª•c.\n")
    return(list(success = FALSE, error = "D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c chu·∫©n h√≥a"))
  } else {
    cat("\n‚úì D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chu·∫©n h√≥a ƒë√∫ng c√°ch.\n")
  }
  
  # B∆∞·ªõc 1: Kh·ªüi t·∫°o giai ƒëo·∫°n A v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
  cat("\nB∆∞·ªõc 1: Kh·ªüi t·∫°o giai ƒëo·∫°n A v·ªõi baseline ph∆∞∆°ng sai (d·ªØ li·ªáu chu·∫©n h√≥a)\n")
  phase_A_standardized <- phase_A_initialization(nlpca_results, VARIABLE_SELECTION_CONFIG)
  
  # B∆∞·ªõc 2: Ti·∫øn h√†nh lo·∫°i bi·∫øn ng∆∞·ª£c v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
  cat("\nB∆∞·ªõc 2: Lo·∫°i bi·∫øn ng∆∞·ª£c d·ª±a tr√™n ph∆∞∆°ng sai tuy·ªát ƒë·ªëi (d·ªØ li·ªáu chu·∫©n h√≥a)\n")
  results <- backward_elimination_threshold_based_standardized(nlpca_results, phase_A_standardized, VARIABLE_SELECTION_CONFIG)
  
  if(results$success) {
    cat("T·ªîNG K·∫æT K·∫æT QU·∫¢ CU·ªêI C√ôNG (D·ªÆ LI·ªÜU ƒê√É CHU·∫®N H√ìA):\n")
    cat("======================================================\n")
    
    initial_vars <- length(phase_A_standardized$Y1_initial)
    final_vars <- length(results$final_variables)
    reduction_pct <- (1 - final_vars/initial_vars) * 100
    
    cat(sprintf("‚Ä¢ Ph∆∞∆°ng ph√°p: %s\n", results$method))
    cat(sprintf("‚Ä¢ D·ªØ li·ªáu s·ª≠ d·ª•ng: ƒê√£ chu·∫©n h√≥a Z-score (%s)\n", 
                ifelse(results$standardized_data_used, "‚úì", "‚úó")))
    cat(sprintf("‚Ä¢ S·ªë th√†nh ph·∫ßn s·ª≠ d·ª•ng: %d (c·ªë ƒë·ªãnh)\n", VARIABLE_SELECTION_CONFIG$nlpca_settings$ndim))
    cat(sprintf("‚Ä¢ S·ªë bi·∫øn ban ƒë·∫ßu: %d\n", initial_vars))
    cat(sprintf("‚Ä¢ S·ªë bi·∫øn ƒë∆∞·ª£c ch·ªçn: %d bi·∫øn\n", final_vars))
    cat(sprintf("‚Ä¢ T·ª∑ l·ªá gi·∫£m bi·∫øn: %.1f%%\n", reduction_pct))
    cat(sprintf("‚Ä¢ Ph∆∞∆°ng sai tuy·ªát ƒë·ªëi cu·ªëi c√πng: %.1f%% (so v·ªõi baseline chu·∫©n h√≥a)\n", results$final_absolute_variance_pct))
    cat(sprintf("‚Ä¢ T·ªïng ph∆∞∆°ng sai baseline: %.4f\n", results$baseline_total_variance))
    cat(sprintf("‚Ä¢ ƒêi·ªÉm ƒë√°nh gi√° cu·ªëi c√πng: %.4f\n", results$final_evaluation$primary_score))
    cat(sprintf("‚Ä¢ L√Ω do d·ª´ng thu·∫≠t to√°n: %s\n", results$stopping_reason))
    cat(sprintf("‚Ä¢ S·ªë v√≤ng l·∫∑p: %d\n", results$iterations))
    
    # ƒê√°nh gi√° l·ª£i √≠ch c·ªßa chu·∫©n h√≥a
    cat("\nL·ª¢I √çCH C·ª¶A CHU·∫®N H√ìA Z-SCORE:\n")
    cat("‚Ä¢ Lo·∫°i b·ªè ·∫£nh h∆∞·ªüng c·ªßa ƒë∆°n v·ªã ƒëo l∆∞·ªùng (VND vs nƒÉm tu·ªïi)\n")
    cat("‚Ä¢ TƒÉng t√≠nh c√¥ng b·∫±ng gi·ªØa c√°c bi·∫øn trong qu√° tr√¨nh NLPCA\n")
    cat("‚Ä¢ C·∫£i thi·ªán ƒë·ªô ·ªïn ƒë·ªãnh c·ªßa thu·∫≠t to√°n t·ªëi ∆∞u h√≥a\n")
    cat("‚Ä¢ K·∫øt qu·∫£ d·ªÖ di·ªÖn gi·∫£i v√† so s√°nh h∆°n\n")
    
    # ƒê√°nh gi√° t√≠nh h·ª£p l·ªá (logic t∆∞∆°ng t·ª±)
    cat("\nKI·ªÇM TRA H·ª¢P L·ªÜ:\n")
    
    if(results$final_absolute_variance_pct >= 60 && results$final_absolute_variance_pct < 100) {
      cat("‚úì Ph∆∞∆°ng sai ƒë·∫°t m·ª©c h·ª£p l√Ω (60-99%) v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a\n")
    } else if(results$final_absolute_variance_pct >= 60) {
      cat("‚ö† Ph∆∞∆°ng sai ch·∫•p nh·∫≠n ƒë∆∞·ª£c nh∆∞ng cao (‚â•60%) v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a\n")
    } else {
      cat("Ph∆∞∆°ng sai d∆∞·ªõi ng∆∞·ª°ng y√™u c·∫ßu (<60%) v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a\n")
    }
    
    if(reduction_pct >= 15 && reduction_pct <= 70) {
      cat("‚úì Gi·∫£m bi·∫øn hi·ªáu qu·∫£ (15-70%)\n")
    } else if(reduction_pct > 70) {
      cat("‚ö† T·ª∑ l·ªá gi·∫£m bi·∫øn cao (>70%) - c√≥ th·ªÉ m·∫•t th√¥ng tin quan tr·ªçng\n")
    } else {
      cat("‚ö† T·ª∑ l·ªá gi·∫£m bi·∫øn th·∫•p (<15%) - ch∆∞a hi·ªáu qu·∫£\n")
    }
    
    if(results$failed_evaluations == 0) {
      cat("‚úì H·ªôi t·ª• ho√†n to√†n (0 l·∫ßn l·ªói ƒë√°nh gi√°) v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a\n")
    } else if(results$failed_evaluations < 5) {
      cat("‚úì H·ªôi t·ª• t·ªët (s·ªë l·∫ßn l·ªói ƒë√°nh gi√° th·∫•p) v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a\n")
    } else {
      cat("‚ö† C√≥ xu·∫•t hi·ªán m·ªôt s·ªë v·∫•n ƒë·ªÅ h·ªôi t·ª• v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a\n")
    }
    
    cat("\nDANH S√ÅCH BI·∫æN ƒê∆Ø·ª¢C CH·ªåN (SAU CHU·∫®N H√ìA):\n")
    cat("-------------------------------------------\n")
    for(i in 1:length(results$final_variables)) {
      var <- results$final_variables[i]
      var_type <- if(var %in% numeric_vars) "[ƒê·ªãnh l∆∞·ª£ng - ƒê√£ chu·∫©n h√≥a]" else "[ƒê·ªãnh t√≠nh]"
      cat(sprintf("  %2d. %-20s %s\n", i, var, var_type))
    }
    
    cat("\nDANH S√ÅCH BI·∫æN B·ªä LO·∫†I B·ªé (theo th·ª© t·ª±):\n")
    cat("----------------------------------------\n")
    if(length(results$removed_variables) > 0) {
      for(i in 1:length(results$removed_variables)) {
        var <- results$removed_variables[i]
        var_type <- if(var %in% numeric_vars) "[ƒê·ªãnh l∆∞·ª£ng]" else "[ƒê·ªãnh t√≠nh]"
        cat(sprintf("  %2d. %-20s %s\n", i, var, var_type))
      }
    } else {
      cat("  (Kh√¥ng c√≥ bi·∫øn n√†o b·ªã lo·∫°i b·ªè)\n")
    }
    
    # ƒê√°nh gi√° t·ªïng th·ªÉ (logic t∆∞∆°ng t·ª±)
    overall_success <- (results$final_absolute_variance_pct >= 60 && 
                       results$final_absolute_variance_pct < 100 &&
                       reduction_pct >= 15 &&
                       results$failed_evaluations < 5 &&
                       results$standardized_data_used)
    
    cat("\nƒê√ÅNH GI√Å T·ªîNG TH·ªÇ:\n")
    if(overall_success) {
      cat("‚úì Thu·∫≠t to√°n th·ª±c thi th√†nh c√¥ng v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a.\n")
      cat("‚úì K·∫øt qu·∫£ tu√¢n th·ªß ƒë√∫ng c√°c ti√™u ch√≠ l·ª±a ch·ªçn bi·∫øn v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a.\n")
      cat("‚úì Logic lo·∫°i bi·∫øn d·ª±a tr√™n ph∆∞∆°ng sai tuy·ªát ƒë·ªëi ƒë·∫£m b·∫£o ƒë√∫ng l√Ω thuy·∫øt.\n")
      cat("‚úì Chu·∫©n h√≥a Z-score ƒë√£ lo·∫°i b·ªè bias do ƒë∆°n v·ªã ƒëo l∆∞·ªùng.\n")
      cat("‚úì K·∫øt qu·∫£ c√≥ √Ω nghƒ©a khoa h·ªçc v√† th·ªëng k√™ cao h∆°n.\n")
    } else {
      cat("‚ö† Thu·∫≠t to√°n c·∫ßn ƒë∆∞·ª£c ki·ªÉm tra, ƒëi·ªÅu ch·ªânh th√™m.\n")
      cat("‚ö† C·∫ßn xem l·∫°i c·∫•u h√¨nh ho·∫∑c quy tr√¨nh chu·∫©n h√≥a d·ªØ li·ªáu.\n")
    }
    
  } else {
    cat("Thu·∫≠t to√°n kh√¥ng th·ª±c hi·ªán th√†nh c√¥ng.\n")
    cat("L·ªói g·∫∑p ph·∫£i: ", results$error, "\n")
  }
  
  return(results)
}

cat("H√†m th·ª±c thi ƒë√£ ƒë∆∞·ª£c c·∫≠p nh·∫≠t cho d·ªØ li·ªáu chu·∫©n h√≥a.\n\n")

# Th·ª±c thi thu·∫≠t to√°n v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a
cat("B·∫Øt ƒë·∫ßu quy tr√¨nh lo·∫°i bi·∫øn v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a Z-score...\n")

if(exists("NLPCA_RESULTS")) {
  
  # Ch·∫°y thu·∫≠t to√°n v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a
  STANDARDIZED_RESULTS <- execute_standardized_backward_elimination(NLPCA_RESULTS)
  
  if(STANDARDIZED_RESULTS$success) {
    cat("\n‚úì Quy tr√¨nh lo·∫°i bi·∫øn v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a ƒë√£ ho√†n th√†nh.\n")
    cat("‚úì K·∫øt qu·∫£ ph√π h·ª£p v√† tu√¢n th·ªß l√Ω thuy·∫øt v·ªõi d·ªØ li·ªáu ƒë√£ chu·∫©n h√≥a.\n")
    cat("‚úì Chu·∫©n h√≥a Z-score ƒë√£ c·∫£i thi·ªán ch·∫•t l∆∞·ª£ng ph√¢n t√≠ch.\n")
  } else {
    cat("\nQuy tr√¨nh th·ª±c thi kh√¥ng th√†nh c√¥ng, c·∫ßn ki·ªÉm tra l·∫°i.\n")
    cat("L·ªói g·∫∑p ph·∫£i: ", STANDARDIZED_RESULTS$error, "\n")
  }
  
} else {
  cat("Kh√¥ng th·ªÉ th·ª±c hi·ªán do thi·∫øu NLPCA_RESULTS.\n")
}
```
